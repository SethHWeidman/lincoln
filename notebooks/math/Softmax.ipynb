{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P$ = class probabilities from last layer of a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P = \\begin{bmatrix}\n",
    "p_1 & p_2 & p_3\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$S$ = probabilities fed through a softmax function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ S = \\begin{bmatrix}\n",
    "\\frac{e^{p_1}}{e^{p_1} + e^{p_2} + e^{p_3}} &\n",
    "\\frac{e^{p_2}}{e^{p_1} + e^{p_2} + e^{p_3}} &\n",
    "\\frac{e^{p_3}}{e^{p_1} + e^{p_2} + e^{p_3}}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\frac{\\partial S}{\\partial P} $ = the correct gradient of softmax?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial S}{\\partial P} = \\begin{bmatrix}\n",
    "\\frac{e^{p_1} * (e^{p_2} + e^{p_3})}{(e^{p_1} + e^{p_2} + e^{p_3})^2} &\n",
    "\\frac{e^{p_2} * (e^{p_1} + e^{p_3})}{(e^{p_1} + e^{p_2} + e^{p_3})^2} &\n",
    "\\frac{e^{p_3} * (e^{p_1} + e^{p_2})}{(e^{p_1} + e^{p_2} + e^{p_3})^2}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think, Mat?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
