{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Lincoln to system path\n",
    "import sys\n",
    "sys.path.append(\"/Users/seth/development/lincoln/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "\n",
    "import typing\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lincoln as lnc\n",
    "from lincoln.operations import Operation, ParamOperation\n",
    "from lincoln.layers import Layer\n",
    "from lincoln.activations import Activation, LinearAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    '''\n",
    "    Once we define all the Operations and the outline of a layer, all that remains to implement here \n",
    "    is the _setup_layer function!\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 neurons: int, \n",
    "                 activation: Activation = LinearAct) -> None:\n",
    "        super().__init__(neurons)\n",
    "        self.activation = activation\n",
    "\n",
    "    def _setup_layer(self, num_in: int) -> None:\n",
    "        # weights\n",
    "        self.params.append(torch.empty(num_in, self.neurons).uniform_(-1, 1))\n",
    "        \n",
    "        # bias\n",
    "        self.params.append(torch.empty(1, self.neurons).uniform_(-1, 1))\n",
    "        \n",
    "        self.operations = [WeightMultiply(self.params[0]), \n",
    "                           BiasAdd(self.params[1])] + [self.activation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightMultiply(ParamOperation):\n",
    "\n",
    "    def __init__(self, \n",
    "                 W: Tensor):\n",
    "        super().__init__(W)\n",
    "    \n",
    "    def _compute_output(self):\n",
    "        return torch.mm(self.input_, self.param)\n",
    "    \n",
    "    def _compute_grads(self, output_grad):\n",
    "        return torch.mm(output_grad, self.param.transpose(0, 1))\n",
    "    \n",
    "    def _param_grad(self, \n",
    "                    output_grad: Tensor):\n",
    "        \n",
    "        return torch.mm(self.input_.transpose(0, 1), output_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 input, 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Tensor([0,1,2,3,4,5,6])\n",
    "fil = Tensor([-1,1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_mid = fil.shape[0] // 2\n",
    "fil_max = 2\n",
    "max_inp = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _min_filter(inp: int, \n",
    "                fil_mid: int):\n",
    "    '''\n",
    "    For Convolution: for an odd filter size and input index, finds the \n",
    "    minimum filter index\n",
    "    '''\n",
    "    if inp < fil_mid:\n",
    "        return fil_mid - inp\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def _max_filter(inp, fil_max, max_inp):\n",
    "    '''\n",
    "    For Convolution: for an odd filter size and input index, finds the \n",
    "    minimum filter index\n",
    "    '''\n",
    "    if max_inp - inp < fil_max:\n",
    "        return max_inp - inp\n",
    "    else:\n",
    "        return fil_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.zeros(inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Tensor([0,1,2,3,4,5,6])\n",
    "fil = Tensor([1,1,1])\n",
    "# out = 1, 3, 6, 9, 12, 15, 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(out.shape[0]):\n",
    "    min_fil = _min_filter(j, fil_mid)\n",
    "    max_fil = _max_filter(j, fil_max, max_inp)\n",
    "    for f, i in zip(range(min_fil, max_fil+1), range(min_fil - fil_mid, max_fil - fil_mid+1)):\n",
    "        out[j] += inp[j+i] * fil[f] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  3.,  6.,  9., 12., 15., 11.])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1D(inp: Tensor, \n",
    "           fil: Tensor) -> Tensor:\n",
    "    '''\n",
    "    1D Convolution with Zero padding\n",
    "    '''\n",
    "    out = torch.zeros(inp.shape)\n",
    "    \n",
    "    for j in range(inp.shape[0]):\n",
    "        min_fil = _min_filter(j, fil_mid)\n",
    "        max_fil = _max_filter(j, fil_max, max_inp)\n",
    "        for f, i in zip(range(min_fil, max_fil+1), range(min_fil - fil_mid, max_fil - fil_mid+1)):\n",
    "            out[j] += inp[j+i] * fil[f] \n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0 -> 0-5 in output, \n",
    "* 1 -> 0-6\n",
    "* 2 -> 1-6\n",
    "\n",
    "Each element in the filter is multiplied by every element in output from `max(ind - filter_mid)` to `min(inp_max - filter_min + ind, inp_max)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1D_param_grad(out_grad: Tensor, \n",
    "                      inp: Tensor, \n",
    "                      param: Tensor) -> Tensor:\n",
    "    '''\n",
    "    1D Convolution with Zero padding\n",
    "    '''\n",
    "    param_grad = torch.zeros(param.shape)\n",
    "    \n",
    "    for j in range(param.shape[0]):\n",
    "        for i, ran(max(ind - filter_mid), range(min_fil - fil_mid, max_fil - fil_mid+1)):\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1D(ParamOperation):\n",
    "\n",
    "    def __init__(self, \n",
    "                 fil: Tensor):\n",
    "        super().__init__(fil)\n",
    "    \n",
    "    def _init_out(self):\n",
    "        self.output = torch.empty(self.input_.shape)\n",
    "    \n",
    "    def _compute_output(self):\n",
    "        for i in self.input_.shape[0]:\n",
    "            \n",
    "    \n",
    "    def _compute_grads(self, output_grad):\n",
    "        return torch.mm(output_grad, self.param.transpose(0, 1))\n",
    "    \n",
    "    def _param_grad(self, \n",
    "                    output_grad: Tensor):\n",
    "        \n",
    "        return torch.mm(self.input_.transpose(0, 1), output_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
