{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Lincoln to system path\n",
    "import sys\n",
    "sys.path.append(\"/Users/seth/development/lincoln/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "import typing\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a simple classifier on the breast cancer dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seth/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/seth/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer = load_breast_cancer()\n",
    "features = breast_cancer.data\n",
    "labels = breast_cancer.target\n",
    "feature_names = breast_cancer.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lincoln.utils import standardize\n",
    "\n",
    "features = standardize(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lincoln as lnc\n",
    "from lincoln.layers import Dense, NeuralNetwork\n",
    "from lincoln.losses import LogSigmoidLoss, MeanSquaredError, LogLoss, Loss\n",
    "from lincoln.optimizers import SGD\n",
    "from lincoln.layers import Layer\n",
    "from lincoln.activations import Sigmoid, LogSigmoid\n",
    "from lincoln.models import Logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Logistic` model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = NeuralNetwork([\n",
    "#     Dense(1, activation=Sigmoid()),\n",
    "# ])\n",
    "\n",
    "# model = Logistic(network,\n",
    "#                  loss=MeanSquaredError(), \n",
    "#                  optimizer=SGD(0.1))\n",
    "\n",
    "# model.fit(features, labels, batch_size=128, log_ps=False,\n",
    "#           epochs=100, print_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something is off..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = lnc.Sequential(\n",
    "#             lnc.layers.Dense(10),\n",
    "#             lnc.layers.Dense(1, activation=LogSigmoid()),\n",
    "#             )\n",
    "# model = Logistic(network,\n",
    "#                  loss=LogSigmoidLoss(network), \n",
    "#                  optimizer=SGD(0.003))\n",
    "# model.fit(features, labels, batch_size=128, log_ps=True,\n",
    "#           epochs=500, print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** `print_every` not working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seth/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "data = boston.data\n",
    "target = boston.target\n",
    "features = boston.feature_names\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "data = s.fit_transform(data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=80718)\n",
    "\n",
    "X_train, X_test, y_train, y_test = Tensor(X_train), Tensor(X_test), Tensor(y_train), Tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4104, -0.4877, -1.3069,  ...,  0.1130,  0.4411, -1.0265],\n",
       "        [ 5.5357, -0.4877,  1.0160,  ...,  0.8066, -3.8822, -0.3565],\n",
       "        [ 9.9417, -0.4877,  1.0160,  ...,  0.8066,  0.4411,  0.6388],\n",
       "        ...,\n",
       "        [-0.3451, -0.4877, -0.4373,  ...,  1.1765,  0.4411, -0.6158],\n",
       "        [-0.4133,  0.5853, -0.9158,  ...,  0.2517,  0.4271, -0.7616],\n",
       "        [-0.3034, -0.4877, -0.4373,  ...,  1.1765,  0.4152,  1.0130]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4144,  3.5896, -1.2339,  ..., -1.7364,  0.3959, -1.2396],\n",
       "        [ 1.6619, -0.4877,  1.0160,  ...,  0.8066,  0.4064,  1.2794],\n",
       "        [ 0.2151, -0.4877,  1.0160,  ...,  0.8066, -0.0152,  0.7117],\n",
       "        ...,\n",
       "        [-0.3880, -0.4877, -0.1805,  ..., -0.0257,  0.4345, -0.1308],\n",
       "        [-0.4139,  1.7656, -0.8487,  ..., -0.8579,  0.4411, -0.7728],\n",
       "        [-0.4161,  3.5896, -1.2339,  ..., -1.7364,  0.3714, -1.3699]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom `Model` class and `train` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lincoln.losses import MeanSquaredError\n",
    "from lincoln.optimizers import SGD\n",
    "from lincoln.utils import permute_data, generate_batch, to_2d\n",
    "\n",
    "from lincoln.activations import LinearAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(object):\n",
    "    def __init__(self, \n",
    "                 network: NeuralNetwork):\n",
    "        self.network = network\n",
    "\n",
    "    def train(self, \n",
    "              X_train: Tensor, \n",
    "              y_train: Tensor,\n",
    "              X_test: Tensor = None,\n",
    "              y_test: Tensor = None,\n",
    "              iterations: int=500, print_every: int=100, \n",
    "              batch_size: int=32, seed: int = 1)-> None:\n",
    " \n",
    "        torch.manual_seed(seed)\n",
    "        y_train, y_test = to_2d(y_train, \"col\"), to_2d(y_test, \"col\")\n",
    "        start = 0\n",
    "\n",
    "        for i in range(iterations):\n",
    "                 \n",
    "            # Generate batch\n",
    "            if start >= X_train.shape[0]:\n",
    "                X_train, y_train = permute_data(X_train, y_train)\n",
    "                start = 0\n",
    "\n",
    "            X_batch, y_batch = generate_batch(X_train, \n",
    "                                              y_train, \n",
    "                                              start, batch_size)\n",
    "\n",
    "            self.network.train_batch(X_batch, y_batch)\n",
    "            \n",
    "            if i % print_every == 0:x\n",
    "                loss = self.network.forward_loss(X_test, y_test)\n",
    "                print(\"Loss: \", loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = NeuralNetwork(\n",
    "    layers=[Dense(neurons=1, \n",
    "                  activation=LinearAct())], \n",
    "            learning_rate=0.0002,\n",
    "            loss = MeanSquaredError())\n",
    "\n",
    "\n",
    "model = LinearModel(network=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(82850.5078)\n",
      "Loss:  tensor(186947.)\n",
      "Loss:  tensor(889866.)\n",
      "Loss:  tensor(2191602.5000)\n",
      "Loss:  tensor(4092166.7500)\n",
      "Loss:  tensor(6591570.)\n",
      "Loss:  tensor(9689808.)\n",
      "Loss:  tensor(13386880.)\n",
      "Loss:  tensor(17682798.)\n",
      "Loss:  tensor(22577560.)\n",
      "Loss:  tensor(28071134.)\n",
      "Loss:  tensor(34163548.)\n",
      "Loss:  tensor(40854828.)\n",
      "Loss:  tensor(48144984.)\n",
      "Loss:  tensor(56033948.)\n",
      "Loss:  tensor(64521732.)\n",
      "Loss:  tensor(73608304.)\n",
      "Loss:  tensor(83293648.)\n",
      "Loss:  tensor(93577808.)\n",
      "Loss:  tensor(104460800.)\n",
      "Loss:  tensor(115942592.)\n",
      "Loss:  tensor(128023192.)\n",
      "Loss:  tensor(140702608.)\n",
      "Loss:  tensor(153980864.)\n",
      "Loss:  tensor(167857968.)\n",
      "Loss:  tensor(182333760.)\n",
      "Loss:  tensor(197408528.)\n",
      "Loss:  tensor(213082160.)\n",
      "Loss:  tensor(229354544.)\n",
      "Loss:  tensor(246225856.)\n",
      "Loss:  tensor(263695904.)\n",
      "Loss:  tensor(281765024.)\n",
      "Loss:  tensor(300433280.)\n",
      "Loss:  tensor(319700384.)\n",
      "Loss:  tensor(339566304.)\n",
      "Loss:  tensor(360031104.)\n",
      "Loss:  tensor(381094784.)\n",
      "Loss:  tensor(402757312.)\n",
      "Loss:  tensor(425018720.)\n",
      "Loss:  tensor(447878784.)\n",
      "Loss:  tensor(471337856.)\n",
      "Loss:  tensor(495395616.)\n",
      "Loss:  tensor(520052352.)\n",
      "Loss:  tensor(545307904.)\n",
      "Loss:  tensor(571162240.)\n",
      "Loss:  tensor(597615488.)\n",
      "Loss:  tensor(624667584.)\n",
      "Loss:  tensor(652318400.)\n",
      "Loss:  tensor(680568384.)\n",
      "Loss:  tensor(709417344.)\n",
      "Loss:  tensor(738865600.)\n",
      "Loss:  tensor(768911872.)\n",
      "Loss:  tensor(799556096.)\n",
      "Loss:  tensor(830799040.)\n",
      "Loss:  tensor(862640896.)\n",
      "Loss:  tensor(895081664.)\n",
      "Loss:  tensor(928120640.)\n",
      "Loss:  tensor(961759232.)\n",
      "Loss:  tensor(995996096.)\n",
      "Loss:  tensor(1030831744.)\n",
      "Loss:  tensor(1066266496.)\n",
      "Loss:  tensor(1102299904.)\n",
      "Loss:  tensor(1138931840.)\n",
      "Loss:  tensor(1176160896.)\n",
      "Loss:  tensor(1213988992.)\n",
      "Loss:  tensor(1252415488.)\n",
      "Loss:  tensor(1291441408.)\n",
      "Loss:  tensor(1331065984.)\n",
      "Loss:  tensor(1371288320.)\n",
      "Loss:  tensor(1412110848.)\n",
      "Loss:  tensor(1453531136.)\n",
      "Loss:  tensor(1495550464.)\n",
      "Loss:  tensor(1538168448.)\n",
      "Loss:  tensor(1581385344.)\n",
      "Loss:  tensor(1625200896.)\n",
      "Loss:  tensor(1669614848.)\n",
      "Loss:  tensor(1714628224.)\n",
      "Loss:  tensor(1760240000.)\n",
      "Loss:  tensor(1806450944.)\n",
      "Loss:  tensor(1853260800.)\n",
      "Loss:  tensor(1900669312.)\n",
      "Loss:  tensor(1948677120.)\n",
      "Loss:  tensor(1997282560.)\n",
      "Loss:  tensor(2046487424.)\n",
      "Loss:  tensor(2096291072.)\n",
      "Loss:  tensor(2146693504.)\n",
      "Loss:  tensor(2197694464.)\n",
      "Loss:  tensor(2249294848.)\n",
      "Loss:  tensor(2301493248.)\n",
      "Loss:  tensor(2354289408.)\n",
      "Loss:  tensor(2407682560.)\n",
      "Loss:  tensor(2461675264.)\n",
      "Loss:  tensor(2516265984.)\n",
      "Loss:  tensor(2571455488.)\n",
      "Loss:  tensor(2627244800.)\n",
      "Loss:  tensor(2683631360.)\n",
      "Loss:  tensor(2740617472.)\n",
      "Loss:  tensor(2798202368.)\n",
      "Loss:  tensor(2856386048.)\n",
      "Loss:  tensor(2915168000.)\n"
     ]
    }
   ],
   "source": [
    "num_iter = 10000\n",
    "print_every = 100\n",
    "\n",
    "model.train(X_train, y_train, X_test, y_test, \n",
    "      iterations = num_iter, \n",
    "      print_every = print_every, \n",
    "      batch_size = 23, \n",
    "      seed=80718);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = NeuralNetwork(\n",
    "    layers=[Dense(neurons=1, \n",
    "                   activation=LinearAct())],\n",
    ")\n",
    "loss = MeanSquaredError()\n",
    "optim = SGD(lr=0.0002)\n",
    "\n",
    "model = LinearModel(network=lr, \n",
    "              loss=MeanSquaredError(), \n",
    "              optimizer=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 1000\n",
    "print_every = 100\n",
    "\n",
    "model.train(X_train, y_train, X_test, y_test, \n",
    "      iterations = num_iter, \n",
    "      print_every = print_every, \n",
    "      batch_size = 23, \n",
    "      seed=80718);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network.layers[0].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
