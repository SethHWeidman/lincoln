{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Lincoln to system path\n",
    "import sys\n",
    "sys.path.append(\"/Users/seth/development/lincoln/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "\n",
    "import typing\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lincoln'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1b4d8df49329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlincoln\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlnc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlincoln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlincoln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogSigmoidLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMeanSquaredError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlincoln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlincoln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSigmoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogSigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lincoln'"
     ]
    }
   ],
   "source": [
    "import lincoln as lnc\n",
    "from lincoln.layers import Dense\n",
    "from lincoln.losses import LogLoss, LogSigmoidLoss, MeanSquaredError\n",
    "from lincoln.optimizers import SGD\n",
    "from lincoln.activations import Sigmoid, LogSigmoid\n",
    "from lincoln.network import NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seth/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/seth/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "data = boston.data\n",
    "target = boston.target\n",
    "features = boston.feature_names\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "data = s.fit_transform(data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=80718)\n",
    "\n",
    "X_train, X_test, y_train, y_test = Tensor(X_train), Tensor(X_test), Tensor(y_train), Tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lincoln.losses import MeanSquaredError\n",
    "from lincoln.optimizers import SGD\n",
    "\n",
    "from lincoln.activations import LinearAct, Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 1 epochs is 4404.868\n",
      "Validation loss after 2 epochs is 3859.566\n",
      "Validation loss after 3 epochs is 3753.522\n",
      "Validation loss after 4 epochs is 3802.207\n",
      "Validation loss after 5 epochs is 3977.285\n",
      "Validation loss after 6 epochs is 3975.196\n",
      "Validation loss after 7 epochs is 4758.660\n",
      "Validation loss after 8 epochs is 4110.424\n",
      "Validation loss after 9 epochs is 3970.611\n",
      "Validation loss after 10 epochs is 4082.891\n"
     ]
    }
   ],
   "source": [
    "lr = NeuralNetwork(\n",
    "    layers=[Dense(neurons=1, \n",
    "                  activation=LinearAct())], \n",
    "            loss = MeanSquaredError(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "lr.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 10,\n",
    "       eval_every = 1,\n",
    "       seed=82618);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return round(torch.mean(torch.abs(y_true - y_pred)).item(), 4)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return round(torch.mean(torch.pow(y_true - y_pred, 2)).item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regression_model(lr: NeuralNetwork, \n",
    "                          X_test: Tensor, \n",
    "                          y_test: Tensor):\n",
    "    preds = lr.forward(X_test)\n",
    "    preds = preds.reshape(preds.shape[0])\n",
    "    return mae(preds, y_test), mse(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.6518, 26.8611)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_regression_model(lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Neural Network\" Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 12.351\n",
      "Validation loss after 20 epochs is 9.482\n",
      "Validation loss after 30 epochs is 8.250\n",
      "Validation loss after 40 epochs is 7.844\n",
      "Validation loss after 50 epochs is 7.199\n",
      "Validation loss after 60 epochs is 6.885\n",
      "Validation loss after 70 epochs is 6.540\n",
      "Validation loss after 80 epochs is 6.380\n",
      "Validation loss after 90 epochs is 6.120\n",
      "Validation loss after 100 epochs is 5.949\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(\n",
    "    layers=[Dense(neurons=13, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=1, \n",
    "                  activation=LinearAct())], \n",
    "            loss = MeanSquaredError(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "nn.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 100,\n",
    "       eval_every = 10,\n",
    "       seed=82618);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2825, 10.3889)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_regression_model(nn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Deep Learning\" Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 2225.604\n",
      "Validation loss after 20 epochs is 2655.737\n",
      "Validation loss after 30 epochs is 1803.951\n",
      "Validation loss after 40 epochs is 1675.552\n",
      "Validation loss after 50 epochs is 1384.854\n",
      "Validation loss after 60 epochs is 1790.974\n",
      "Validation loss after 70 epochs is 1282.833\n",
      "Validation loss after 80 epochs is 1245.037\n",
      "Validation loss after 90 epochs is 1302.036\n",
      "Validation loss after 100 epochs is 1333.448\n"
     ]
    }
   ],
   "source": [
    "dl = NeuralNetwork(\n",
    "    layers=[Dense(neurons=13, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=13, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=1, \n",
    "                  activation=LinearAct())], \n",
    "            loss = MeanSquaredError(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "dl.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 100,\n",
    "       eval_every = 10,\n",
    "       seed=82618);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0576, 8.7727)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_regression_model(dl, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data prep (SciKit Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer = load_breast_cancer()\n",
    "data = breast_cancer.data\n",
    "target = breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "data = s.fit_transform(data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=82618)\n",
    "\n",
    "X_train, X_test, y_train, y_test = Tensor(X_train), Tensor(X_test), Tensor(y_train), Tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"`LogSigmoid`\" Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 23.003\n",
      "Validation loss after 20 epochs is 19.236\n",
      "Validation loss after 30 epochs is nan\n",
      "Validation loss after 40 epochs is nan\n",
      "Validation loss after 50 epochs is nan\n",
      "Validation loss after 60 epochs is nan\n",
      "Validation loss after 70 epochs is nan\n",
      "Validation loss after 80 epochs is nan\n",
      "Validation loss after 90 epochs is nan\n",
      "Validation loss after 100 epochs is nan\n"
     ]
    }
   ],
   "source": [
    "logr = NeuralNetwork(\n",
    "    layers=[Dense(neurons=1, \n",
    "                  activation=LogSigmoid())],\n",
    "            loss = LogSigmoidLoss(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "logr.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 100,\n",
    "       eval_every = 10,\n",
    "       seed=82618);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something off with trying to predict log probabilities here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"`LogLoss`\" Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 23.003\n",
      "Validation loss after 20 epochs is 19.236\n",
      "Validation loss after 30 epochs is 18.084\n",
      "Validation loss after 40 epochs is 17.586\n",
      "Validation loss after 50 epochs is 17.340\n",
      "Validation loss after 60 epochs is 17.210\n",
      "Validation loss after 70 epochs is 17.109\n",
      "Validation loss after 80 epochs is 17.062\n",
      "Validation loss after 90 epochs is 17.031\n",
      "Validation loss after 100 epochs is 17.020\n"
     ]
    }
   ],
   "source": [
    "logr = NeuralNetwork(\n",
    "    layers=[Dense(neurons=1, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = LogLoss(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "logr.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 100,\n",
    "       eval_every = 10,\n",
    "       seed=82618);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return round(torch.sum(torch.eq(y_true, y_pred)).item() / y_true.size()[0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classification_model(model: NeuralNetwork, \n",
    "                              X_test: Tensor, \n",
    "                              y_test: Tensor):\n",
    "    preds = model.forward(X_test)\n",
    "    preds = preds > 0.5\n",
    "    preds = preds.reshape(preds.shape[0]).type(torch.FloatTensor)  \n",
    "    return accuracy(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classification_model(logr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LogLoss` works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"`MSE`\" Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 50 epochs is 5.118\n",
      "Validation loss after 100 epochs is 4.190\n",
      "Validation loss after 150 epochs is 3.970\n",
      "Validation loss after 200 epochs is 3.852\n",
      "Validation loss after 250 epochs is 3.773\n",
      "Validation loss after 300 epochs is 3.718\n",
      "Validation loss after 350 epochs is 3.680\n",
      "Validation loss after 400 epochs is 3.659\n",
      "Validation loss after 450 epochs is 3.664\n",
      "Validation loss after 500 epochs is 3.703\n"
     ]
    }
   ],
   "source": [
    "logr_mse = NeuralNetwork(\n",
    "    layers=[Dense(neurons=1, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = MeanSquaredError(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "logr_mse.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 500,\n",
    "       eval_every = 50,\n",
    "       seed=82618);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return round(torch.sum(torch.eq(y_true, y_pred)).item() / y_true.size()[0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classification_model(model: NeuralNetwork, \n",
    "                              X_test: Tensor, \n",
    "                              y_test: Tensor):\n",
    "    preds = model.forward(X_test)\n",
    "    preds = preds > 0.5\n",
    "    preds = preds.reshape(preds.shape[0]).type(torch.FloatTensor)  \n",
    "    return accuracy(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classification_model(logr_mse, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Works!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Neural Network\" Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 50 epochs is 7.861\n",
      "Validation loss after 100 epochs is 6.662\n",
      "Validation loss after 150 epochs is 5.946\n",
      "Validation loss after 200 epochs is 5.438\n",
      "Validation loss after 250 epochs is 5.053\n",
      "Validation loss after 300 epochs is 4.753\n",
      "Validation loss after 350 epochs is 4.513\n",
      "Validation loss after 400 epochs is 4.322\n",
      "Validation loss after 450 epochs is 4.171\n",
      "Validation loss after 500 epochs is 4.052\n"
     ]
    }
   ],
   "source": [
    "logr_nn = NeuralNetwork(\n",
    "    layers=[Dense(neurons=30, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=1, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = MeanSquaredError(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "logr_nn.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 500,\n",
    "       eval_every = 50,\n",
    "       seed=82618);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classification_model(logr_nn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Works!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
