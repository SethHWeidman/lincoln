{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add Lincoln to system path\n",
    "import sys\n",
    "sys.path.append(\"/Users/seth/development/lincoln/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from lincoln.layers import Dense\n",
    "from lincoln.losses import LogSoftmaxLoss, LogSigmoidLoss, MeanSquaredError\n",
    "from lincoln.optimizers import SGD\n",
    "from lincoln.operations.activations import Sigmoid, LogSigmoid\n",
    "from lincoln.network import NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "data = boston.data\n",
    "target = boston.target\n",
    "features = boston.feature_names\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "data = s.fit_transform(data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=80718)\n",
    "\n",
    "X_train, X_test, y_train, y_test = Tensor(X_train), Tensor(X_test), Tensor(y_train), Tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lincoln.losses import MeanSquaredError\n",
    "from lincoln.optimizers import SGD\n",
    "\n",
    "from lincoln.operations.activations import Sigmoid, LinearAct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 1 epochs is 4404.868\n",
      "Validation loss after 2 epochs is 3859.566\n",
      "Validation loss after 3 epochs is 3753.522\n",
      "Validation loss after 4 epochs is 3802.207\n",
      "Validation loss after 5 epochs is 3977.285\n",
      "Validation loss after 6 epochs is 3975.196\n",
      "Validation loss after 7 epochs is 4758.660\n",
      "Validation loss after 8 epochs is 4110.424\n",
      "Validation loss after 9 epochs is 3970.611\n",
      "Validation loss after 10 epochs is 4082.891\n"
     ]
    }
   ],
   "source": [
    "lr = NeuralNetwork(\n",
    "    layers=[Dense(neurons=1, \n",
    "                  activation=LinearAct())], \n",
    "            loss = MeanSquaredError(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "lr.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 10,\n",
    "       eval_every = 1,\n",
    "       seed=82618,\n",
    "       single_output=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return round(torch.mean(torch.abs(y_true - y_pred)).item(), 4)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return round(torch.mean(torch.pow(y_true - y_pred, 2)).item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regression_model(lr: NeuralNetwork, \n",
    "                          X_test: Tensor, \n",
    "                          y_test: Tensor):\n",
    "    preds = lr.forward(X_test)\n",
    "    preds = preds.reshape(preds.shape[0])\n",
    "    return mae(preds, y_test), mse(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.6518, 26.8611)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_regression_model(lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Neural Network\" Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 2421.626\n",
      "Validation loss after 20 epochs is 1583.616\n",
      "Validation loss after 30 epochs is 1485.388\n",
      "Validation loss after 40 epochs is 1567.009\n",
      "Validation loss after 50 epochs is 1532.060\n",
      "Validation loss after 60 epochs is 1729.032\n",
      "Validation loss after 70 epochs is 1768.350\n",
      "Validation loss after 80 epochs is 1659.488\n",
      "Validation loss after 90 epochs is 1612.138\n",
      "Validation loss after 100 epochs is 1579.115\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(\n",
    "    layers=[Dense(neurons=13, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=1, \n",
    "                  activation=LinearAct())], \n",
    "            loss = MeanSquaredError(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "nn.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 100,\n",
    "       eval_every = 10,\n",
    "       seed=82618,\n",
    "           single_output=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2825, 10.3889)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_regression_model(nn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Deep Learning\" Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 2225.604\n",
      "Validation loss after 20 epochs is 2655.737\n",
      "Validation loss after 30 epochs is 1803.951\n",
      "Validation loss after 40 epochs is 1675.552\n",
      "Validation loss after 50 epochs is 1384.854\n",
      "Validation loss after 60 epochs is 1790.974\n",
      "Validation loss after 70 epochs is 1282.833\n",
      "Validation loss after 80 epochs is 1245.037\n",
      "Validation loss after 90 epochs is 1302.036\n",
      "Validation loss after 100 epochs is 1333.448\n"
     ]
    }
   ],
   "source": [
    "dl = NeuralNetwork(\n",
    "    layers=[Dense(neurons=13, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=13, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=1, \n",
    "                  activation=LinearAct())], \n",
    "            loss = MeanSquaredError(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "dl.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 100,\n",
    "       eval_every = 10,\n",
    "       seed=82618,\n",
    "           single_output=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0576, 8.7727)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_regression_model(dl, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data prep (SciKit Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer = load_breast_cancer()\n",
    "data = breast_cancer.data\n",
    "target = breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "data = s.fit_transform(data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=82618)\n",
    "\n",
    "X_train, X_test, y_train, y_test = Tensor(X_train), Tensor(X_test), Tensor(y_train), Tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"`LogSigmoid`\" Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 23.003\n",
      "Validation loss after 20 epochs is 19.235\n",
      "Validation loss after 30 epochs is 18.084\n",
      "Validation loss after 40 epochs is 17.586\n",
      "Validation loss after 50 epochs is 17.340\n",
      "Validation loss after 60 epochs is 17.210\n",
      "Validation loss after 70 epochs is 17.108\n",
      "Validation loss after 80 epochs is 17.061\n",
      "Validation loss after 90 epochs is 17.031\n",
      "Validation loss after 100 epochs is 17.019\n"
     ]
    }
   ],
   "source": [
    "logr = NeuralNetwork(\n",
    "    layers=[Dense(neurons=1, \n",
    "                  activation=LogSigmoid())],\n",
    "            loss = LogSigmoidLoss(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "logr.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 100,\n",
    "       eval_every = 10,\n",
    "       seed=82618,\n",
    "           single_output=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 10.025\n",
      "Validation loss after 20 epochs is 7.280\n",
      "Validation loss after 30 epochs is 6.160\n",
      "Validation loss after 40 epochs is 5.527\n",
      "Validation loss after 50 epochs is 5.118\n",
      "Validation loss after 60 epochs is 4.818\n",
      "Validation loss after 70 epochs is 4.576\n",
      "Validation loss after 80 epochs is 4.395\n",
      "Validation loss after 90 epochs is 4.274\n",
      "Validation loss after 100 epochs is 4.190\n"
     ]
    }
   ],
   "source": [
    "logr_mse = NeuralNetwork(\n",
    "    layers=[Dense(neurons=1, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = MeanSquaredError(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "logr_mse.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 100,\n",
    "       eval_every = 10,\n",
    "       seed=82618,\n",
    "           single_output=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return round(torch.sum(torch.eq(y_true, y_pred)).item() / y_true.size()[0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classification_model(model: NeuralNetwork, \n",
    "                              X_test: Tensor, \n",
    "                              y_test: Tensor,\n",
    "                              log_probs: bool = False):\n",
    "    preds = model.forward(X_test)\n",
    "    if log_probs:\n",
    "        preds = torch.exp(preds)\n",
    "    preds = preds > 0.5\n",
    "    preds = preds.reshape(preds.shape[0]).type(torch.FloatTensor)  \n",
    "    return accuracy(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classification_model(logr, X_test, y_test, log_probs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9708"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classification_model(logr_mse, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LogSoftmaxLoss` works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Neural Network\" Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 50 epochs is 7.861\n",
      "Validation loss after 100 epochs is 6.662\n",
      "Validation loss after 150 epochs is 5.946\n",
      "Validation loss after 200 epochs is 5.438\n",
      "Validation loss after 250 epochs is 5.053\n",
      "Validation loss after 300 epochs is 4.753\n",
      "Validation loss after 350 epochs is 4.513\n",
      "Validation loss after 400 epochs is 4.322\n",
      "Validation loss after 450 epochs is 4.171\n",
      "Validation loss after 500 epochs is 4.052\n"
     ]
    }
   ],
   "source": [
    "logr_nn = NeuralNetwork(\n",
    "    layers=[Dense(neurons=30, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=1, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = MeanSquaredError(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "logr_nn.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 500,\n",
    "       eval_every = 50,\n",
    "       seed=82618,\n",
    "           single_output=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classification_model(logr_nn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Works!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Demos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Old losses and layers code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lincoln.layers import Conv2D\n",
    "from lincoln.operations.activations import ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "mnist_trainset = MNIST(root=\"./explanatory/data\", train=True, download=False, transform=None)\n",
    "mnist_testset = MNIST(root=\"./explanatory/data\", train=False, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mnist_trainset\n",
    "num_labels = len(data.train_labels)\n",
    "train_labels = torch.zeros(num_labels, 10)\n",
    "for i in range(num_labels):\n",
    "    train_labels[i][data.train_labels[i]] = 1\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 10])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mnist_testset\n",
    "num_labels = len(data.test_labels)\n",
    "test_labels = torch.zeros(num_labels, 10)\n",
    "for i in range(num_labels):\n",
    "    test_labels[i][data.test_labels[i]] = 1\n",
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = mnist_trainset.train_data.type(torch.float32).unsqueeze(3) / 255.0\n",
    "mnist_test = mnist_testset.test_data.type(torch.float32).unsqueeze(3) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist_train\n",
    "X_test = mnist_test\n",
    "y_train = train_labels\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv_transform(input_: Tensor) -> Tensor:\n",
    "\n",
    "    return input_.view(input_.shape[0],\n",
    "                       input_.shape[1] * input_.shape[2] * input_.shape[3])\n",
    "\n",
    "X_train_flat = _conv_transform(X_train)\n",
    "X_test_flat = _conv_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_nn_ll = NeuralNetwork(\n",
    "    layers=[Dense(neurons=250, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=50, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = LogSoftmaxLoss(),\n",
    "            optimizer = SGD(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 1 epochs is 23464.492\n",
      "Training took 3.4 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "conv_nn_ll.fit(X_train_flat, y_train, X_test_flat, y_test,  \n",
    "        epochs=1,\n",
    "        eval_every=1,\n",
    "        batch_size=100,\n",
    "        seed=91418);\n",
    "print(\"Training took\", round(time.time()-start, 1), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_nn(nn, X_test, y_test):\n",
    "    test_preds = nn.forward(X_test)\n",
    "    \n",
    "    test_preds_l = torch.argmax(test_preds, dim=1)\n",
    "    \n",
    "    test_vals_l = torch.argmax(y_test, dim=1)\n",
    "    \n",
    "    return torch.sum(test_preds_l == test_vals_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9311)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_nn(conv_nn_ll, X_test_flat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_perm = X_train.permute(0, 3, 1, 2)\n",
    "X_test_perm = X_test.permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "pytorch = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_nn_logloss = NeuralNetwork(\n",
    "    layers=[Conv2D(param_size=3,\n",
    "                   out_channels=24,\n",
    "                   activation=ReLU(),\n",
    "                   pytorch=pytorch),\n",
    "            Conv2D(param_size=3,\n",
    "                   out_channels=30,\n",
    "                   activation=ReLU(),\n",
    "                   pytorch=pytorch,\n",
    "                   flatten=True),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = LogSoftmaxLoss(),\n",
    "            optimizer = SGD(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "conv_nn_logloss.fit(X_train_perm, y_train, X_test_perm, y_test,  \n",
    "        epochs=1,\n",
    "        eval_every=1,\n",
    "        batch_size=100,\n",
    "        seed=91418);\n",
    "print(\"Training took\", round(time.time()-start, 1), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_nn(conv_nn_logloss, X_test_perm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing network without PyTorch layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch = False\n",
    "cython = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_nn_normal = NeuralNetwork(\n",
    "    layers=[Conv2D(param_size=3,\n",
    "                   out_channels=24,\n",
    "                   activation=ReLU(),\n",
    "                   pytorch=pytorch,\n",
    "                   cython=cython),\n",
    "            Conv2D(param_size=3,\n",
    "                   out_channels=30,\n",
    "                   activation=ReLU(),\n",
    "                   pytorch=pytorch,\n",
    "                   cython=cython,\n",
    "                   flatten=True),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = LogSoftmaxLoss(),\n",
    "            optimizer = SGD(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "conv_nn_normal.fit(X_train_perm, y_train, X_test_perm, y_test,  \n",
    "        epochs=1,\n",
    "        eval_every=1,\n",
    "        batch_size=1,\n",
    "        seed=91418);\n",
    "print(\"Training took\", round(time.time()-start, 1), \"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch = False\n",
    "cython = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_nn_cython = NeuralNetwork(\n",
    "    layers=[Conv2D(param_size=3,\n",
    "                   out_channels=24,\n",
    "                   activation=ReLU(),\n",
    "                   pytorch=pytorch,\n",
    "                   cython=cython),\n",
    "            Conv2D(param_size=3,\n",
    "                   out_channels=30,\n",
    "                   activation=ReLU(),\n",
    "                   pytorch=pytorch,\n",
    "                   cython=cython,\n",
    "                   flatten=True),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = LogSoftmaxLoss(),\n",
    "            optimizer = SGD(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "conv_nn_cython.fit(X_train_perm, y_train, X_test_perm, y_test,  \n",
    "        epochs=1,\n",
    "        eval_every=1,\n",
    "        batch_size=1,\n",
    "        seed=91418);\n",
    "print(\"Training took\", round(time.time()-start, 1), \"seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
