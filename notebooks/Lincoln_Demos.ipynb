{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Lincoln to system path\n",
    "import sys\n",
    "sys.path.append(\"/Users/seth/development/lincoln/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "\n",
    "import typing\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lincoln as lnc\n",
    "from lincoln.layers import Dense\n",
    "from lincoln.losses import LogSigmoidLoss, MeanSquaredError\n",
    "from lincoln.optimizers import SGD\n",
    "from lincoln.activations import Sigmoid, LogSigmoid\n",
    "from lincoln.network import NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seth/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/seth/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "data = boston.data\n",
    "target = boston.target\n",
    "features = boston.feature_names\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "data = s.fit_transform(data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=80718)\n",
    "\n",
    "X_train, X_test, y_train, y_test = Tensor(X_train), Tensor(X_test), Tensor(y_train), Tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lincoln.losses import MeanSquaredError\n",
    "from lincoln.optimizers import SGD\n",
    "\n",
    "from lincoln.activations import LinearAct, Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 1 epochs is 4404.868\n",
      "Validation loss after 2 epochs is 3859.566\n",
      "Validation loss after 3 epochs is 3753.522\n",
      "Validation loss after 4 epochs is 3802.207\n",
      "Validation loss after 5 epochs is 3977.285\n",
      "Validation loss after 6 epochs is 3975.196\n",
      "Validation loss after 7 epochs is 4758.660\n",
      "Validation loss after 8 epochs is 4110.424\n",
      "Validation loss after 9 epochs is 3970.611\n",
      "Validation loss after 10 epochs is 4082.891\n"
     ]
    }
   ],
   "source": [
    "lr = NeuralNetwork(\n",
    "    layers=[Dense(neurons=1, \n",
    "                  activation=LinearAct())], \n",
    "            loss = MeanSquaredError(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "lr.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 10,\n",
    "       eval_every = 1,\n",
    "       seed=82618);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return round(torch.mean(torch.abs(y_true - y_pred)).item(), 4)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return round(torch.mean(torch.pow(y_true - y_pred, 2)).item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regression_model(lr: NeuralNetwork, \n",
    "                          X_test: Tensor, \n",
    "                          y_test: Tensor):\n",
    "    preds = lr.forward(X_test)\n",
    "    preds = preds.reshape(preds.shape[0])\n",
    "    return mae(preds, y_test), mse(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.6518, 26.8611)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_regression_model(lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 2421.626\n",
      "Validation loss after 20 epochs is 1583.616\n",
      "Validation loss after 30 epochs is 1485.388\n",
      "Validation loss after 40 epochs is 1567.009\n",
      "Validation loss after 50 epochs is 1532.060\n",
      "Validation loss after 60 epochs is 1729.032\n",
      "Validation loss after 70 epochs is 1768.350\n",
      "Validation loss after 80 epochs is 1659.488\n",
      "Validation loss after 90 epochs is 1612.138\n",
      "Validation loss after 100 epochs is 1579.115\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(\n",
    "    layers=[Dense(neurons=13, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=1, \n",
    "                  activation=LinearAct())], \n",
    "            loss = MeanSquaredError(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "nn.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 100,\n",
    "       eval_every = 10,\n",
    "       seed=82618);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2825, 10.3889)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_regression_model(nn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 2225.604\n",
      "Validation loss after 20 epochs is 2655.737\n",
      "Validation loss after 30 epochs is 1803.951\n",
      "Validation loss after 40 epochs is 1675.552\n",
      "Validation loss after 50 epochs is 1384.854\n",
      "Validation loss after 60 epochs is 1790.974\n",
      "Validation loss after 70 epochs is 1282.833\n",
      "Validation loss after 80 epochs is 1245.037\n",
      "Validation loss after 90 epochs is 1302.036\n",
      "Validation loss after 100 epochs is 1333.448\n"
     ]
    }
   ],
   "source": [
    "dl = NeuralNetwork(\n",
    "    layers=[Dense(neurons=13, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=13, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=1, \n",
    "                  activation=LinearAct())], \n",
    "            loss = MeanSquaredError(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "dl.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 100,\n",
    "       eval_every = 10,\n",
    "       seed=82618);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0576, 8.7727)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_regression_model(dl, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer = load_breast_cancer()\n",
    "data = breast_cancer.data\n",
    "target = breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "data = s.fit_transform(data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=82618)\n",
    "\n",
    "X_train, X_test, y_train, y_test = Tensor(X_train), Tensor(X_test), Tensor(y_train), Tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b48f145c0e94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m        \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m        \u001b[0meval_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m        seed=82618);\n\u001b[0m",
      "\u001b[0;32m~/development/lincoln/lincoln/network.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_test, y_test, epochs, eval_every, batch_size, seed)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meval_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/lincoln/lincoln/network.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, X_batch, y_batch)\u001b[0m\n\u001b[1;32m     74\u001b[0m                     y_batch: Tensor) -> float:\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/lincoln/lincoln/network.py\u001b[0m in \u001b[0;36mforward_loss\u001b[0;34m(self, X_batch, y_batch)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     def train_batch(self, \n",
      "\u001b[0;32m~/development/lincoln/lincoln/losses.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, predictions, target)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexp_z\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mexp_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0massert_same_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "logr = NeuralNetwork(\n",
    "    layers=[Dense(neurons=1, \n",
    "                  activation=LogSigmoid())],\n",
    "            loss = LogSigmoidLoss(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "logr.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 100,\n",
    "       eval_every = 10,\n",
    "       seed=82618);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something off with trying to predict log probabilities here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = NeuralNetwork(\n",
    "    layers=[Dense(neurons=1, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = MeanSquaredError(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "logr.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 500,\n",
    "       eval_every = 50,\n",
    "       seed=82618);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return round(torch.sum(torch.eq(y_true, y_pred)).item() / y_true.size()[0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classification_model(model: NeuralNetwork, \n",
    "                              X_test: Tensor, \n",
    "                              y_test: Tensor):\n",
    "    preds = model.forward(X_test)\n",
    "    preds = preds > 0.5\n",
    "    preds = preds.reshape(preds.shape[0]).type(torch.FloatTensor)  \n",
    "    return accuracy(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_classification_model(logr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_nn = NeuralNetwork(\n",
    "    layers=[Dense(neurons=30, \n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=1, \n",
    "                  activation=Sigmoid())],\n",
    "            loss = MeanSquaredError(),\n",
    "            optimizer = SGD())\n",
    "\n",
    "logr_nn.fit(X_train, y_train, X_test, y_test,  \n",
    "       epochs = 500,\n",
    "       eval_every = 50,\n",
    "       seed=82618);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_classification_model(logr_nn, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
