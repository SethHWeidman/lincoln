{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Lincoln to system path\n",
    "import sys\n",
    "sys.path.append(\"/Users/seth/development/lincoln/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "import typing\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a simple classifier on the breast cancer dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seth/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/seth/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer = load_breast_cancer()\n",
    "features = breast_cancer.data\n",
    "labels = breast_cancer.target\n",
    "feature_names = breast_cancer.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lincoln.utils import standardize\n",
    "\n",
    "features = standardize(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lincoln as lnc\n",
    "from lincoln.layers import Dense, NeuralNetwork\n",
    "from lincoln.losses import LogSigmoidLoss, MeanSquaredError, LogLoss, Loss\n",
    "from lincoln.optimizers import SGD\n",
    "from lincoln.layers import Layer\n",
    "from lincoln.activations import Sigmoid, LogSigmoid\n",
    "from lincoln.models import Logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Logistic` model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = NeuralNetwork([\n",
    "#     Dense(1, activation=Sigmoid()),\n",
    "# ])\n",
    "\n",
    "# model = Logistic(network,\n",
    "#                  loss=MeanSquaredError(), \n",
    "#                  optimizer=SGD(0.1))\n",
    "\n",
    "# model.fit(features, labels, batch_size=128, log_ps=False,\n",
    "#           epochs=100, print_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something is off..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = lnc.Sequential(\n",
    "#             lnc.layers.Dense(10),\n",
    "#             lnc.layers.Dense(1, activation=LogSigmoid()),\n",
    "#             )\n",
    "# model = Logistic(network,\n",
    "#                  loss=LogSigmoidLoss(network), \n",
    "#                  optimizer=SGD(0.003))\n",
    "# model.fit(features, labels, batch_size=128, log_ps=True,\n",
    "#           epochs=500, print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** `print_every` not working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seth/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "data = boston.data\n",
    "target = boston.target\n",
    "features = boston.feature_names\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "data = s.fit_transform(data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=80718)\n",
    "\n",
    "X_train, X_test, y_train, y_test = Tensor(X_train), Tensor(X_test), Tensor(y_train), Tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom `Model` class and `train` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lincoln.losses import MeanSquaredError\n",
    "from lincoln.optimizers import SGD\n",
    "from lincoln.utils import permute_data, generate_batch, to_2d\n",
    "\n",
    "from lincoln.activations import LinearAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(object):\n",
    "    def __init__(self, \n",
    "                 network: NeuralNetwork):\n",
    "        self.network = network\n",
    "\n",
    "    def train(self, \n",
    "              X_train: Tensor, \n",
    "              y_train: Tensor,\n",
    "              X_test: Tensor = None,\n",
    "              y_test: Tensor = None,\n",
    "              iterations: int=500, print_every: int=100, \n",
    "              batch_size: int=32, seed: int = 1)-> None:\n",
    " \n",
    "        torch.manual_seed(seed)\n",
    "        y_train, y_test = to_2d(y_train, \"col\"), to_2d(y_test, \"col\")\n",
    "        start = 0\n",
    "\n",
    "        for i in range(iterations):\n",
    "                 \n",
    "            # Generate batch\n",
    "            if start >= X_train.shape[0]:\n",
    "                X_train, y_train = permute_data(X_train, y_train)\n",
    "                start = 0\n",
    "\n",
    "            X_batch, y_batch = generate_batch(X_train, \n",
    "                                              y_train, \n",
    "                                              start, batch_size)\n",
    "\n",
    "            self.network.train_batch(X_batch, y_batch)\n",
    "            \n",
    "            if i % print_every == 0:\n",
    "                loss = self.network.forward_loss(X_test, y_test)\n",
    "                print(\"Loss: \", loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = NeuralNetwork(\n",
    "    layers=[Dense(neurons=1, \n",
    "                  activation=LinearAct())], \n",
    "            learning_rate=0.0002,\n",
    "            loss = MeanSquaredError())\n",
    "\n",
    "\n",
    "model = LinearModel(network=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(82850.5078)\n",
      "Loss:  tensor(67651.3516)\n",
      "Loss:  tensor(57402.3750)\n",
      "Loss:  tensor(49771.3438)\n",
      "Loss:  tensor(43768.3203)\n",
      "Loss:  tensor(38882.3555)\n",
      "Loss:  tensor(34814.5312)\n",
      "Loss:  tensor(31374.4102)\n",
      "Loss:  tensor(28432.3574)\n",
      "Loss:  tensor(25895.2539)\n"
     ]
    }
   ],
   "source": [
    "num_iter = 100\n",
    "print_every = 10\n",
    "\n",
    "model.train(X_train, y_train, X_test, y_test, \n",
    "      iterations = num_iter, \n",
    "      print_every = print_every, \n",
    "      batch_size = 23, \n",
    "      seed=80718);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
