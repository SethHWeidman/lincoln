{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Lincoln to system path\n",
    "import sys\n",
    "sys.path.append(\"/Users/seth/development/lincoln/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "\n",
    "import typing\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lincoln as lnc\n",
    "from lincoln.operations import Operation, ParamOperation\n",
    "from lincoln.layers import Layer\n",
    "from lincoln.activations import Activation, LinearAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    '''\n",
    "    Once we define all the Operations and the outline of a layer, all that remains to implement here \n",
    "    is the _setup_layer function!\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 neurons: int, \n",
    "                 activation: Activation = LinearAct) -> None:\n",
    "        super().__init__(neurons)\n",
    "        self.activation = activation\n",
    "\n",
    "    def _setup_layer(self, num_in: int) -> None:\n",
    "        # weights\n",
    "        self.params.append(torch.empty(num_in, self.neurons).uniform_(-1, 1))\n",
    "        \n",
    "        # bias\n",
    "        self.params.append(torch.empty(1, self.neurons).uniform_(-1, 1))\n",
    "        \n",
    "        self.operations = [WeightMultiply(self.params[0]), \n",
    "                           BiasAdd(self.params[1])] + [self.activation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightMultiply(ParamOperation):\n",
    "\n",
    "    def __init__(self, \n",
    "                 W: Tensor):\n",
    "        super().__init__(W)\n",
    "    \n",
    "    def _compute_output(self):\n",
    "        return torch.mm(self.input_, self.param)\n",
    "    \n",
    "    def _compute_grads(self, output_grad):\n",
    "        return torch.mm(output_grad, self.param.transpose(0, 1))\n",
    "    \n",
    "    def _param_grad(self, \n",
    "                    output_grad: Tensor):\n",
    "        \n",
    "        return torch.mm(self.input_.transpose(0, 1), output_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_same_shape(output: Tensor, \n",
    "                      output_grad: Tensor):\n",
    "    assert output.shape == output_grad.shape, \\\n",
    "    '''\n",
    "    Two tensors should have the same shape; instead, first Tensor's shape is {0}\n",
    "    and second Tensor's shape is {1}.\n",
    "    '''.format(tuple(output_grad.shape), tuple(output.shape))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 input, 1 output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_1d(inp: Tensor,\n",
    "            num: int) -> Tensor:\n",
    "    z = torch.Tensor([0])\n",
    "    z = z.repeat(num)\n",
    "    return torch.cat([z, inp, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 2., 3., 4., 5., 6., 0.])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pad_1d(inp1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_1d(inp: Tensor, \n",
    "            fil: Tensor) -> Tensor:\n",
    "    \n",
    "    fil_len = fil.shape[0]\n",
    "    fil_mid = fil_len // 2\n",
    "    inp_pad = _pad_1d(inp, fil_mid)\n",
    "    \n",
    "    out = torch.zeros(inp.shape)\n",
    "    \n",
    "    for o in range(out.shape[0]):\n",
    "        for f in range(fil_len):\n",
    "            out[o] += fil[f] * inp_pad[o+f]\n",
    "\n",
    "    assert_same_shape(inp, out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = Tensor([0,1,2,3,4,5,6])\n",
    "fil1 = Tensor([1,1,1])\n",
    "fil2 = Tensor([2,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  3.,  6.,  9., 12., 15., 11.])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d(inp1, fil1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_1d(inp1, fil2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_1d_sum(inp: Tensor, \n",
    "                fil: Tensor) -> Tensor:\n",
    "    out = conv_1d(inp, fil)\n",
    "    return torch.sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(57.)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_sum(inp1, fil1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(72.)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_sum(inp1, fil2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _param_grad(inp: Tensor, \n",
    "                fil: Tensor, \n",
    "                output_grad: Tensor = None) -> Tensor:\n",
    "    \n",
    "    fil_len = fil.shape[0]\n",
    "    fil_mid = fil_len // 2\n",
    "    inp_pad = _pad_1d(inp, fil_mid)\n",
    "    \n",
    "    if not output_grad:\n",
    "        out_grad = torch.ones_like(inp)\n",
    "    else:\n",
    "        assert_same_shape(inp, out_grad)\n",
    "    \n",
    "    out_pad = _pad_1d(out_grad, fil_mid)\n",
    "    \n",
    "    # Zero padded 1 dimensional convolution\n",
    "    param_grad = torch.zeros_like(fil)\n",
    "    input_grad = torch.zeros_like(inp)\n",
    "\n",
    "    for f in range(fil.shape[0]):\n",
    "        for o in range(inp.shape[0]):\n",
    "            param_grad[f] += inp_pad[o+f] * out_grad[o]\n",
    "            input_grad[o] += out_pad[o+fil_len-f-1] * fil[f]\n",
    "        \n",
    "    assert_same_shape(param_grad, fil)\n",
    "    assert_same_shape(input_grad, inp)\n",
    "    return param_grad, input_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_t = Tensor([0,1,2,3,4,5,6])\n",
    "fil_t = Tensor([1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_grad(inp: Tensor,\n",
    "                fil: Tensor):\n",
    "    \n",
    "    inp_grad_check = torch.zeros_like(inp)\n",
    "    fil_grad_check = torch.zeros_like(fil)\n",
    "\n",
    "    for i in range(inp.shape[0]):\n",
    "        inp_temp = inp.clone()\n",
    "        inp_temp[i] = inp_temp[i] + 1\n",
    "        sum1 = conv_1d_sum(inp, fil).item()\n",
    "        sum2 = conv_1d_sum(inp_temp, fil).item()\n",
    "        inp_grad_check[i] = sum2 - sum1\n",
    "\n",
    "    for f in range(fil.shape[0]):\n",
    "        fil_temp = fil.clone()\n",
    "        fil_temp[f] = fil_temp[f] + 1\n",
    "        sum1 = conv_1d_sum(inp, fil).item()\n",
    "        sum2 = conv_1d_sum(inp, fil_temp).item()\n",
    "        fil_grad_check[f] = sum2 - sum1\n",
    "        \n",
    "    return fil_grad_check, inp_grad_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([15., 21., 21.]), tensor([2., 3., 3., 3., 3., 3., 2.]))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_param_grad(inp_t, fil_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([15., 21., 21.]), tensor([2., 3., 3., 3., 3., 3., 2.]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_check_grad(inp_t, fil_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _min_filter(inp: int, \n",
    "                fil_mid: int):\n",
    "    '''\n",
    "    For Convolution: for an odd filter size and input index, finds the \n",
    "    minimum filter index\n",
    "    '''\n",
    "    if inp < fil_mid:\n",
    "        return fil_mid - inp\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def _max_filter(inp, fil_max, max_inp):\n",
    "    '''\n",
    "    For Convolution: for an odd filter size and input index, finds the \n",
    "    minimum filter index\n",
    "    '''\n",
    "    if max_inp - inp < fil_max:\n",
    "        return max_inp - inp\n",
    "    else:\n",
    "        return fil_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.zeros(inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Tensor([0,1,2,3,4,5,6])\n",
    "fil = Tensor([1,1,1])\n",
    "# out = 1, 3, 6, 9, 12, 15, 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(out.shape[0]):\n",
    "    min_fil = _min_filter(j, fil_mid)\n",
    "    max_fil = _max_filter(j, fil_max, max_inp)\n",
    "    for f, i in zip(range(min_fil, max_fil+1), range(min_fil - fil_mid, max_fil - fil_mid+1)):\n",
    "        out[j] += inp[j+i] * fil[f] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  3.,  6.,  9., 12., 15., 11.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the output.\n",
    "\n",
    "The filter gets multiplied by the same elements in the input.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(len(fil)):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1D(inp: Tensor, \n",
    "           fil: Tensor) -> Tensor:\n",
    "    '''\n",
    "    1D Convolution with Zero padding\n",
    "    '''\n",
    "    out = torch.zeros(inp.shape)\n",
    "    \n",
    "    for j in range(inp.shape[0]):\n",
    "        min_fil = _min_filter(j, fil_mid)\n",
    "        max_fil = _max_filter(j, fil_max, max_inp)\n",
    "        for f, i in zip(range(min_fil, max_fil+1), range(min_fil - fil_mid, max_fil - fil_mid+1)):\n",
    "            out[j] += inp[j+i] * fil[f] \n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1D_param_grad(out_grad: Tensor, \n",
    "                      inp: Tensor, \n",
    "                      param: Tensor) -> Tensor:\n",
    "    '''\n",
    "    1D Convolution with Zero padding\n",
    "    '''\n",
    "    param_grad = torch.zeros(param.shape)\n",
    "    \n",
    "    for j in range(param.shape[0]):\n",
    "        for i, ran(max(ind - filter_mid), range(min_fil - fil_mid, max_fil - fil_mid+1)):\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1D(ParamOperation):\n",
    "\n",
    "    def __init__(self, \n",
    "                 fil: Tensor):\n",
    "        super().__init__(fil)\n",
    "    \n",
    "    def _init_out(self):\n",
    "        self.output = torch.empty(self.input_.shape)\n",
    "    \n",
    "    def _compute_output(self):\n",
    "        for i in self.input_.shape[0]:\n",
    "            \n",
    "    \n",
    "    def _compute_grads(self, output_grad):\n",
    "        return torch.mm(output_grad, self.param.transpose(0, 1))\n",
    "    \n",
    "    def _param_grad(self, \n",
    "                    output_grad: Tensor):\n",
    "        \n",
    "        return torch.mm(self.input_.transpose(0, 1), output_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
