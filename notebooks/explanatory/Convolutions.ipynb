{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Lincoln to system path\n",
    "import sys\n",
    "sys.path.append(\"/Users/seth/development/lincoln/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "\n",
    "import typing\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lincoln.operations import Operation, ParamOperation\n",
    "from lincoln.layers import Layer\n",
    "from lincoln.activations import Activation, LinearAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    '''\n",
    "    Once we define all the Operations and the outline of a layer, all that remains to implement here \n",
    "    is the _setup_layer function!\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 neurons: int, \n",
    "                 activation: Activation = LinearAct) -> None:\n",
    "        super().__init__(neurons)\n",
    "        self.activation = activation\n",
    "\n",
    "    def _setup_layer(self, num_in: int) -> None:\n",
    "        # weights\n",
    "        self.params.append(torch.empty(num_in, self.neurons).uniform_(-1, 1))\n",
    "        \n",
    "        # bias\n",
    "        self.params.append(torch.empty(1, self.neurons).uniform_(-1, 1))\n",
    "        \n",
    "        self.operations = [WeightMultiply(self.params[0]), \n",
    "                           BiasAdd(self.params[1])] + [self.activation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightMultiply(ParamOperation):\n",
    "\n",
    "    def __init__(self, \n",
    "                 W: Tensor):\n",
    "        super().__init__(W)\n",
    "    \n",
    "    def _compute_output(self):\n",
    "        return torch.mm(self.input_, self.param)\n",
    "    \n",
    "    def _compute_grads(self, output_grad):\n",
    "        return torch.mm(output_grad, self.param.transpose(0, 1))\n",
    "    \n",
    "    def _param_grad(self, \n",
    "                    output_grad: Tensor):\n",
    "        \n",
    "        return torch.mm(self.input_.transpose(0, 1), output_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_same_shape(output: Tensor, \n",
    "                      output_grad: Tensor):\n",
    "    assert output.shape == output_grad.shape, \\\n",
    "    '''\n",
    "    Two tensors should have the same shape; instead, first Tensor's shape is {0}\n",
    "    and second Tensor's shape is {1}.\n",
    "    '''.format(tuple(output_grad.shape), tuple(output.shape))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 input, 1 output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_1d(inp: Tensor,\n",
    "            num: int) -> Tensor:\n",
    "    z = torch.Tensor([0])\n",
    "    z = z.repeat(num)\n",
    "    return torch.cat([z, inp, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_1d(inp: Tensor, \n",
    "            fil: Tensor) -> Tensor:\n",
    "    \n",
    "    fil_len = fil.shape[0]\n",
    "    fil_mid = fil_len // 2\n",
    "    inp_pad = _pad_1d(inp, fil_mid)\n",
    "    \n",
    "    out = torch.zeros(inp.shape)\n",
    "    \n",
    "    for o in range(out.shape[0]):\n",
    "        for f in range(fil_len):\n",
    "            out[o] += fil[f] * inp_pad[o+f]\n",
    "\n",
    "    assert_same_shape(inp, out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = Tensor([0,1,2,3,4,5,6])\n",
    "fil1 = Tensor([1,1,1])\n",
    "fil2 = Tensor([2,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  3.,  6.,  9., 12., 15., 11.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d(inp1, fil1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  3.,  7., 11., 15., 19., 16.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d(inp1, fil2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_1d_sum(inp: Tensor, \n",
    "                fil: Tensor) -> Tensor:\n",
    "    out = conv_1d(inp, fil)\n",
    "    return torch.sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(57.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_sum(inp1, fil1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(72.)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_sum(inp1, fil2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _param_grad(inp: Tensor, \n",
    "                fil: Tensor, \n",
    "                output_grad: Tensor = None) -> Tensor:\n",
    "    \n",
    "    fil_len = fil.shape[0]\n",
    "    fil_mid = fil_len // 2\n",
    "    inp_pad = _pad_1d(inp, fil_mid)\n",
    "    \n",
    "    if output_grad is None:\n",
    "        output_grad = torch.ones_like(inp)\n",
    "    else:\n",
    "        assert_same_shape(inp, output_grad)\n",
    "    \n",
    "    output_pad = _pad_1d(output_grad, fil_mid)\n",
    "    \n",
    "    # Zero padded 1 dimensional convolution\n",
    "    param_grad = torch.zeros_like(fil)\n",
    "    input_grad = torch.zeros_like(inp)\n",
    "\n",
    "    for f in range(fil.shape[0]):\n",
    "        for o in range(inp.shape[0]):\n",
    "            param_grad[f] += inp_pad[o+f] * output_grad[o]\n",
    "            input_grad[o] += output_pad[o+fil_len-f-1] * fil[f]\n",
    "        \n",
    "    assert_same_shape(param_grad, fil)\n",
    "    assert_same_shape(input_grad, inp)\n",
    "    return param_grad, input_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_t = Tensor([0,1,2,3,4,5,6])\n",
    "fil_t = Tensor([1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_grad(inp: Tensor,\n",
    "                fil: Tensor):\n",
    "    \n",
    "    inp_grad_check = torch.zeros_like(inp)\n",
    "    fil_grad_check = torch.zeros_like(fil)\n",
    "\n",
    "    for i in range(inp.shape[0]):\n",
    "        inp_temp = inp.clone()\n",
    "        inp_temp[i] = inp_temp[i] + 1\n",
    "        sum1 = conv_1d_sum(inp, fil).item()\n",
    "        sum2 = conv_1d_sum(inp_temp, fil).item()\n",
    "        inp_grad_check[i] = sum2 - sum1\n",
    "\n",
    "    for f in range(fil.shape[0]):\n",
    "        fil_temp = fil.clone()\n",
    "        fil_temp[f] = fil_temp[f] + 1\n",
    "        sum1 = conv_1d_sum(inp, fil).item()\n",
    "        sum2 = conv_1d_sum(inp, fil_temp).item()\n",
    "        fil_grad_check[f] = sum2 - sum1\n",
    "        \n",
    "    return fil_grad_check, inp_grad_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([15., 21., 21.]), tensor([2., 3., 3., 3., 3., 3., 2.]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_param_grad(inp_t, fil_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([15., 21., 21.]), tensor([2., 3., 3., 3., 3., 3., 2.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_check_grad(inp_t, fil_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_t = Tensor([[0,1,2,3,4,5,6], \n",
    "                [1,2,3,4,5,6,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_1d(inp: Tensor,\n",
    "            num: int) -> Tensor:\n",
    "    z = torch.Tensor([0])\n",
    "    z = z.repeat(num)\n",
    "    return torch.cat([z, inp, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_1d_batch(inp: Tensor, \n",
    "                  num: int) -> Tensor:\n",
    "    outs = [_pad_1d(obs, num) for obs in inp]\n",
    "    return torch.stack(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 2., 3., 4., 5., 6., 0.],\n",
       "        [0., 1., 2., 3., 4., 5., 6., 7., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pad_1d_batch(inp_t, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_1d_batch(inp: Tensor, \n",
    "                  fil: Tensor) -> Tensor:\n",
    "\n",
    "    outs = [conv_1d(obs, fil) for obs in inp]\n",
    "    return torch.stack(outs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  3.,  6.,  9., 12., 15., 11.],\n",
       "        [ 3.,  6.,  9., 12., 15., 18., 13.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_batch(inp_t, fil1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_1d_batch(inp: Tensor, \n",
    "                  fil: Tensor) -> Tensor:\n",
    "\n",
    "    out = conv_1d_batch(inp, fil)\n",
    "    \n",
    "    out_grad = torch.ones_like(out)\n",
    "        \n",
    "    grads = [_param_grad(inp[i], fil, out_grad[i])[1] for i in range(output_grad.shape[0])]    \n",
    "\n",
    "    return torch.stack(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_grad_1d_batch(inp: Tensor, \n",
    "                        fil: Tensor) -> Tensor:\n",
    "\n",
    "    output_grad = torch.ones_like(inp)\n",
    "    \n",
    "    inp_pad = _pad_1d_batch(inp, 1)\n",
    "    out_pad = _pad_1d_batch(inp, 1)\n",
    "\n",
    "    param_grad = torch.ones_like(fil)    \n",
    "    \n",
    "    for i in range(inp.shape[0]):\n",
    "        for p in range(fil.shape[0]):\n",
    "            for o in range(inp.shape[1]):\n",
    "                param_grad[p] += inp_pad[i][o+p] * output_grad[i][o]    \n",
    "    return param_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing conv + weight multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just `param_grad_1d_batch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_grad_1d_batch(inp: Tensor, \n",
    "                        fil: Tensor, \n",
    "                        output_grad: Tensor) -> Tensor:\n",
    "\n",
    "    inp_pad = _pad_1d_batch(inp, 1)\n",
    "    out_pad = _pad_1d_batch(inp, 1)\n",
    "    param_grad = torch.zeros_like(fil)    \n",
    "    \n",
    "    for i in range(inp.shape[0]):\n",
    "        for p in range(fil.shape[0]):\n",
    "            for o in range(inp.shape[1]):\n",
    "                param_grad[p] += inp_pad[i][o+p] * output_grad[i][o]    \n",
    "    return param_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_conv(inp: Tensor, \n",
    "                     fil: Tensor):\n",
    "    conv_out = conv_1d_batch(inp, fil)\n",
    "\n",
    "    return round(torch.sum(conv_out).item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4595, -0.0404,  0.7231,  0.9657,  0.9637, -0.6279,  0.7466],\n",
      "        [ 0.8894, -0.9637,  0.1816,  0.4596,  0.6427, -0.0797, -0.8224]])\n",
      "tensor([ 0.7842, -0.3495, -0.1091])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(83118)\n",
    "inp_t = Tensor(2, 7).uniform_(-1, 1)\n",
    "fil = Tensor(torch.empty(3).uniform_(-1, 1))\n",
    "print(inp_t)\n",
    "print(fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9457"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_conv(inp_t, fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_grad = torch.ones_like(inp_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.6545, 2.5786, 2.1487])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grad_1d_batch(inp_t, \n",
    "                    fil, \n",
    "                    output_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fil_grad[0] = 2.6545`\n",
    "\n",
    "Adding 0.1 to `fil[0]` should change the sum to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2111"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(0.9457 + 0.1 * 2.6545, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8842, -0.3495, -0.1091])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil2 = torch.clone(fil)\n",
    "fil2[0] += 0.1\n",
    "fil2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2112"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_conv(inp_t, fil2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking input gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4346,  0.3255,  0.3255,  0.3255,  0.3255,  0.3255, -0.4587],\n",
       "        [ 0.4346,  0.3255,  0.3255,  0.3255,  0.3255,  0.3255, -0.4587]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_1d_batch(inp_t, fil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`inp_t[0][0]`'s gradient is `0.4346`. So increasing it by 0.1 should increase the sum to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9892"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(0.9457 + 0.1 * 0.4346, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3595, -0.0404,  0.7231,  0.9657,  0.9637, -0.6279,  0.7466],\n",
       "        [ 0.8894, -0.9637,  0.1816,  0.4596,  0.6427, -0.0797, -0.8224]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_t2 = inp_t.clone()\n",
    "inp_t2[0][0] += 0.1\n",
    "inp_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9892"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_conv(inp_t2, fil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With weight multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.8207"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_t = Tensor(2, 7).uniform_(-1, 1)\n",
    "fil = Tensor(torch.empty(3).uniform_(-1, 1))\n",
    "weights = Tensor(torch.empty(7, 5).uniform_(-1, 1))\n",
    "\n",
    "conv_out = conv_1d_batch(inp_t, fil)\n",
    "\n",
    "out = torch.mm(conv_out, weights)\n",
    "\n",
    "round(torch.sum(out).item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4404,  0.2923, -0.1474])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_grad = torch.mm(torch.ones_like(out), weights.transpose(0, 1))\n",
    "\n",
    "fil_grad = param_grad_1d_batch(inp_t, fil, out_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7563, 1.8538, 7.7927])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fil_grad[0] = 2.7563`\n",
    "\n",
    "Adding 0.1 to `FIL[0]` should change the sum to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5451"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(-1.8207 + 0.1 * 2.7563, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_conv_mul(inp: Tensor, \n",
    "                     fil: Tensor, \n",
    "                     weights: Tensor):\n",
    "    conv_out = conv_1d_batch(inp_t, fil)\n",
    "\n",
    "    out = torch.mm(conv_out, weights)\n",
    "\n",
    "    return round(torch.sum(out).item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3404,  0.2923, -0.1474])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil2 = torch.clone(fil)\n",
    "fil2[0] += 0.1\n",
    "fil2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.545"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_conv_mul(inp_t, fil2, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operation(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def forward(self, \n",
    "                input_: Tensor):\n",
    "        self.input_ = input_\n",
    "        \n",
    "        self.output = self._compute_output()\n",
    "\n",
    "        return self.output\n",
    "    \n",
    "\n",
    "    def _input_grad(self, output_grad: Tensor) -> Tensor:\n",
    "        assert_same_shape(self.output, output_grad)       \n",
    "        \n",
    "        input_grad = self._compute_grads(output_grad)\n",
    "               \n",
    "        assert_same_shape(self.input_, input_grad)\n",
    "        return input_grad\n",
    "    \n",
    "\n",
    "    def backward(self, output_grad: Tensor) -> Tensor:\n",
    "        return self._input_grad(output_grad)\n",
    "\n",
    "    def _compute_output(self, input_: Tensor) -> Tensor:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def _compute_grads(self, output_grad: Tensor) -> Tensor:\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "\n",
    "class ParamOperation(Operation):\n",
    "\n",
    "    def __init__(self, param: Tensor) -> Tensor:\n",
    "        super().__init__()\n",
    "        self.param = param\n",
    "        \n",
    "    def backward(self, output_grad: Tensor) -> Tensor:\n",
    "        \n",
    "        self.param_grad = self._param_grad(output_grad)\n",
    "        \n",
    "        assert_same_shape(self.param, self.param_grad)\n",
    "        \n",
    "        return self._input_grad(output_grad)\n",
    "        \n",
    "    def _param_grad(self, output_grad: Tensor) -> Tensor:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1D(ParamOperation):\n",
    "\n",
    "    def __init__(self, \n",
    "                 param: Tensor):\n",
    "        super().__init__(param)\n",
    "        self.param_size = param.shape[0]\n",
    "        self.param_pad = self.param_size // 2\n",
    "        \n",
    "    def _pad_1d_obs(self, obs: Tensor) -> Tensor:\n",
    "        z = torch.Tensor([0])\n",
    "        z = z.repeat(self.param_pad)\n",
    "        return torch.cat([z, obs, z])\n",
    "\n",
    "    def _pad_1d(self, inp: Tensor) -> Tensor:\n",
    "        outs = [self._pad_1d_obs(obs) for obs in inp]\n",
    "        return torch.stack(outs)    \n",
    "\n",
    "    def _compute_output_obs(self, obs: Tensor):\n",
    "        \n",
    "        obs_pad = self._pad_1d_obs(obs)\n",
    "\n",
    "        out = torch.zeros(obs.shape)\n",
    "\n",
    "        for o in range(out.shape[0]):\n",
    "            for p in range(self.param_size):\n",
    "                out[o] += self.param[p] * obs_pad[o+p]\n",
    "        return out\n",
    "    \n",
    "    def _compute_output(self):\n",
    "        \n",
    "        outs = [self._compute_output_obs(obs) for obs in self.input_]\n",
    "        return torch.stack(outs)\n",
    "    \n",
    "    def _compute_grads_obs(self, \n",
    "                           input_obs: Tensor,\n",
    "                           output_grad_obs: Tensor) -> None:\n",
    "\n",
    "        output_obs_pad = self._pad_1d_obs(output_grad_obs)\n",
    "        input_obs_pad = self._pad_1d_obs(input_obs)\n",
    "        input_grad = torch.zeros_like(input_obs)\n",
    "\n",
    "        for p in range(self.param.shape[0]):\n",
    "            for o in range(input_obs.shape[0]):\n",
    "                input_grad[o] += output_obs_pad[o+self.param_size-p-1] * self.param[p]\n",
    "                \n",
    "        return input_grad\n",
    "        \n",
    "    def _compute_grads(self, output_grad: Tensor) -> None:\n",
    "        \n",
    "        grads = [self._compute_grads_obs(self.input_[i], output_grad[i]) for i in range(output_grad.shape[0])]    \n",
    "\n",
    "        return torch.stack(grads)\n",
    "\n",
    "    def _param_grad(self, output_grad: Tensor) -> Tensor:\n",
    "\n",
    "        inp_pad = self._pad_1d(self.input_)\n",
    "        out_pad = self._pad_1d(output_grad)\n",
    "\n",
    "        param_grad = torch.zeros_like(self.param)\n",
    "\n",
    "        for i in range(self.input_.shape[0]):\n",
    "            for p in range(self.param.shape[0]):\n",
    "                for o in range(self.input_.shape[1]):\n",
    "                    param_grad[p] += inp_pad[i][o+p] * output_grad[i][o]\n",
    "        \n",
    "        return param_grad\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4404,  0.2923, -0.1474])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1779,  0.6374, -0.8940, -0.3311, -0.0193],\n",
       "        [-0.1690,  0.0073,  0.8437,  0.9426,  0.6066],\n",
       "        [ 0.4668,  0.5077, -0.6763,  0.0992, -0.4717],\n",
       "        [ 0.0476, -0.3656,  0.7781, -0.5844,  0.8515],\n",
       "        [ 0.8489,  0.6374,  0.6090,  0.6846,  0.5798],\n",
       "        [-0.6807,  0.3116, -0.1502, -0.3789, -0.1404],\n",
       "        [ 0.4816,  0.8886,  0.8650, -0.4064, -0.2798]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestConv(Layer):\n",
    "    '''\n",
    "    Once we define all the Operations and the outline of a layer, all that remains to implement here \n",
    "    is the _setup_layer function!\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 neurons: int, \n",
    "                 activation: Activation = LinearAct,\n",
    "                 filter_size: int = 3) -> None:\n",
    "        super().__init__(neurons)\n",
    "        self.activation = activation\n",
    "        self.filter_size = filter_size\n",
    "        \n",
    "\n",
    "    def _setup_layer(self, num_in: int) -> None:\n",
    "        # filter\n",
    "        self.params.append(Tensor([-0.4404,  0.2923, -0.1474]))\n",
    "        \n",
    "        # Weights\n",
    "        self.params.append(Tensor([[ 0.1779,  0.6374, -0.8940, -0.3311, -0.0193],\n",
    "        [-0.1690,  0.0073,  0.8437,  0.9426,  0.6066],\n",
    "        [ 0.4668,  0.5077, -0.6763,  0.0992, -0.4717],\n",
    "        [ 0.0476, -0.3656,  0.7781, -0.5844,  0.8515],\n",
    "        [ 0.8489,  0.6374,  0.6090,  0.6846,  0.5798],\n",
    "        [-0.6807,  0.3116, -0.1502, -0.3789, -0.1404],\n",
    "        [ 0.4816,  0.8886,  0.8650, -0.4064, -0.2798]]))\n",
    "        \n",
    "        self.operations = [Conv1D(self.params[0]),\n",
    "                           WeightMultiply(self.params[1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TestConv(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3163, -0.1501,  0.7113,  0.3191,  0.6163,  0.7247, -0.0049],\n",
       "        [-0.1855,  0.7793,  0.8862, -0.1635, -0.4434,  0.8358,  0.8314]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0912, -0.1621, -0.6499,  0.3251, -0.3171],\n",
       "        [-0.5356, -0.1283, -0.2132,  0.2433, -0.2916]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = a.forward(Tensor(inp_t))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.8206"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(a.forward(Tensor(inp_t)).sum().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1080,  0.7482, -0.6709, -1.2561,  1.3323, -1.4810,  0.6059],\n",
       "        [-1.1080,  0.7482, -0.6709, -1.2561,  1.3323, -1.4810,  0.6059]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.backward(torch.ones_like(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7561, 1.8538, 7.7929])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a._param_grads()\n",
    "\n",
    "a.operations[0].param_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tensor([2.7563, 1.8538, 7.7927])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks out! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist_trainset = MNIST(root=\"./data\", train=True, download=False, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = mnist_trainset.train_data.type(torch.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_imgs = mnist_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mnist_imgs, \"../speedup/data/img_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist_imgs_2 = torch.load(\"img_batch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_imgs_2_np = mnist_imgs_2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_imgs_2_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pad = 2\n",
    "obs = np.zeros(28)\n",
    "a = np.zeros(pad)\n",
    "np.concatenate([a, obs, a]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(90118)\n",
    "fil = Tensor(torch.empty(3, 3).uniform_(-1, 1))\n",
    "fil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy:\n",
    "\n",
    "1. `_pad_2d_obs`\n",
    "2. `_pad_2d`\n",
    "3. `_compute_output_obs`\n",
    "4. `_compute_output`\n",
    "\n",
    "The hard part:\n",
    "\n",
    "5. `_compute_grads`\n",
    "6. `_compute_grads_obs`\n",
    "\n",
    "For 5 and 6: can use the \"CNN_Explanation\" notebook as a guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_imgs = mnist_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_2d_obs(inp: Tensor, \n",
    "                num: int):\n",
    "    '''\n",
    "    Input is a 2 dimensional, square, 2D Tensor\n",
    "    '''\n",
    "    \n",
    "    inp_pad = _pad_1d_batch(inp, num)\n",
    "    other = torch.zeros(num, inp.shape[0] + num * 2)\n",
    "    return torch.cat([other, inp_pad, other])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_1d_batch(inp: Tensor, \n",
    "                  num: int) -> Tensor:\n",
    "#     import pdb; pdb.set_trace()\n",
    "    outs = [_pad_1d(obs, num) for obs in inp]\n",
    "\n",
    "    return torch.stack(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_1d(inp: Tensor,\n",
    "            num: int) -> Tensor:\n",
    "    z = torch.Tensor([0])\n",
    "    z = z.repeat(num)\n",
    "#     import pdb; pdb.set_trace()\n",
    "    return torch.cat([z, inp, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_img[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pad_2d_obs(mnist_img[0], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_2d(inp: Tensor, \n",
    "            num: int):\n",
    "    '''\n",
    "    Input is a 3 dimensional tensor, first dimension batch size\n",
    "    '''\n",
    "\n",
    "    outs = [_pad_2d_obs(obs, num) for obs in inp]\n",
    "    return torch.stack(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pad_2d(mnist_imgs, 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1D**:\n",
    "\n",
    "```python\n",
    "    def _compute_output_obs(self, obs: Tensor):\n",
    "        \n",
    "        obs_pad = self._pad_1d_obs(obs)\n",
    "\n",
    "        out = torch.zeros(obs.shape)\n",
    "\n",
    "        for o in range(out.shape[0]):\n",
    "            for p in range(self.param_size):\n",
    "                out[o] += self.param[p] * obs_pad[o+p]\n",
    "        return out\n",
    "    \n",
    "    def _compute_output(self):\n",
    "        \n",
    "        outs = [self._compute_output_obs(obs) for obs in self.input_]\n",
    "        return torch.stack(outs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_output_obs_2d(obs: Tensor, \n",
    "                           param: Tensor):\n",
    "    '''\n",
    "    Obs is a 2d square Tensor, so is param\n",
    "    '''\n",
    "    param_mid = param.shape[0] // 2\n",
    "    \n",
    "    obs_pad = _pad_2d_obs(obs, param_mid)\n",
    "    \n",
    "    out = torch.zeros(obs.shape)\n",
    "    \n",
    "    for o_w in range(out.shape[0]):\n",
    "        for o_h in range(out.shape[1]):\n",
    "            for p_w in range(param.shape[0]):\n",
    "                for p_h in range(param.shape[1]):\n",
    "                    out[o_w][o_h] += param[p_w][p_h] * obs_pad[o_w+p_w][o_h+p_h]\n",
    "    return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_compute_output_obs_2d(mnist_imgs[0], fil).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_compute_output_obs_2d(torch.ones_like(mnist_imgs[0]), \n",
    "                   torch.ones_like(fil)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_output_2d(img_batch: Tensor,\n",
    "                       param: Tensor):\n",
    "    \n",
    "    outs = [_compute_output_obs_2d(obs, param) for obs in img_batch]\n",
    "    return torch.stack(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_compute_output_2d(mnist_imgs, fil).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Param grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "def _compute_grads_obs(self, \n",
    "                       input_obs: Tensor,\n",
    "                       output_grad_obs: Tensor) -> None:\n",
    "\n",
    "    output_obs_pad = self._pad_1d_obs(output_grad_obs)\n",
    "    input_obs_pad = self._pad_1d_obs(input_obs)\n",
    "    input_grad = torch.zeros_like(input_obs)\n",
    "\n",
    "    for p in range(self.param.shape[0]):\n",
    "        for o in range(input_obs.shape[0]):\n",
    "            input_grad[o] += output_obs_pad[o+self.param_size-p-1] * self.param[p]\n",
    "\n",
    "    return input_grad\n",
    "\n",
    "def _compute_grads(self, output_grad: Tensor) -> None:\n",
    "\n",
    "    grads = [self._compute_grads_obs(self.input_[i], output_grad[i]) for i in range(output_grad.shape[0])]    \n",
    "\n",
    "    return torch.stack(grads)\n",
    "\n",
    "def _param_grad(self, output_grad: Tensor) -> Tensor:\n",
    "\n",
    "    inp_pad = self._pad_1d(self.input_)\n",
    "    out_pad = self._pad_1d(output_grad)\n",
    "\n",
    "    param_grad = torch.zeros_like(self.param)\n",
    "\n",
    "    for i in range(self.input_.shape[0]):\n",
    "        for p in range(self.param.shape[0]):\n",
    "            for o in range(self.input_.shape[1]):\n",
    "                param_grad[p] += inp_pad[i][o+p] * output_grad[i][o]\n",
    "\n",
    "    return param_grad\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_grads_obs_2d(input_obs: Tensor,\n",
    "                          output_grad_obs: Tensor, \n",
    "                          param: Tensor) -> Tensor:\n",
    "    '''\n",
    "    input_obs: 2D Tensor representing the input observation\n",
    "    output_grad_obs: 2D Tensor representing the output gradient  \n",
    "    param: 2D filter\n",
    "    '''\n",
    "    \n",
    "    param_size = param.shape[0]\n",
    "    output_obs_pad = _pad_2d_obs(output_grad_obs, param_size // 2)\n",
    "    input_grad = torch.zeros_like(input_obs)\n",
    "    \n",
    "    for i_w in range(input_obs.shape[0]):\n",
    "        for i_h in range(input_obs.shape[1]):\n",
    "            for p_w in range(param_size):\n",
    "                for p_h in range(param_size):\n",
    "                    input_grad[i_w][i_h] += output_obs_pad[i_w+param_size-p_w-1][i_h+param_size-p_h-1] \\\n",
    "                    * param[p_w][p_h]\n",
    "\n",
    "    return input_grad\n",
    "\n",
    "def _compute_grads_2d(inp: Tensor,\n",
    "                      output_grad: Tensor, \n",
    "                      param: Tensor) -> Tensor:\n",
    "\n",
    "    grads = [_compute_grads_obs_2d(inp[i], output_grad[i], param) for i in range(output_grad.shape[0])]    \n",
    "\n",
    "    return torch.stack(grads)\n",
    "\n",
    "\n",
    "\n",
    "def _param_grad_2d(inp: Tensor,\n",
    "                output_grad: Tensor, \n",
    "                param: Tensor) -> Tensor:\n",
    "\n",
    "    param_size = param.shape[0]\n",
    "    inp_pad = _pad_2d(inp, param_size // 2)\n",
    "\n",
    "    param_grad = torch.zeros_like(param)\n",
    "    img_shape = output_grad.shape[1:]\n",
    "    \n",
    "    for i in range(inp.shape[0]):\n",
    "        for o_w in range(img_shape[0]):\n",
    "            for o_h in range(img_shape[1]):\n",
    "                for p_w in range(param_size):\n",
    "                    for p_h in range(param_size):\n",
    "                        param_grad[p_w][p_h] += inp_pad[i][o_w+p_w][o_h+p_h] \\\n",
    "                        * output_grad[i][o_w][o_h]\n",
    "    return param_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_grads = _compute_grads_2d(mnist_imgs, \n",
    "                  torch.ones_like(mnist_imgs),\n",
    "                  fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_param_grad(mnist_imgs, \n",
    "            torch.ones_like(mnist_imgs),\n",
    "            fil).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_param_grad(torch.ones_like(mnist_imgs), \n",
    "            torch.ones_like(mnist_imgs),\n",
    "            torch.ones_like(fil))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(83118)\n",
    "inp_2d = Tensor(2, 28, 28).uniform_(-1, 1)\n",
    "fil_2d = Tensor(torch.empty(3, 3).uniform_(-1, 1))\n",
    "print(inp_2d)\n",
    "print(fil_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = _compute_output_2d(inp_2d, fil_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_grad_2d = torch.ones_like(inp_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing input gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_grads_2d = _compute_grads_2d(inp_2d, out_grad_2d, fil_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_grads_2d[1][1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`inp_grads_2d[1][1][1] = 0.1522` That means if we increase `inp_2d[1][1][1]` by 0.1, the sum will increase to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(4.3893 + 0.1 * 0.1522, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_2d_sum(inp: Tensor, \n",
    "                fil: Tensor):\n",
    "    out = _compute_output_2d(inp, fil)\n",
    "    return torch.sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_2d_2 = inp_2d.clone()\n",
    "inp_2d_2[1][1][1] += 0.1\n",
    "inp_2d_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conv_2d_sum(inp_2d, fil_2d))\n",
    "print(conv_2d_sum(inp_2d_2, fil_2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing param gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grads_2d = _param_grad(inp_2d, out_grad_2d, fil)\n",
    "param_grads_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`param_grads_2d[1][1] = 9.9202` That means if we increase `param_grads_2d[1][1]` by 0.1, the sum will increase to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(4.3893 + 9.9202 * 0.1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_2d_2 = fil_2d.clone()\n",
    "fil_2d_2[1][1] += 0.1\n",
    "fil_2d_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conv_2d_sum(inp_2d, fil_2d))\n",
    "print(conv_2d_sum(inp_2d, fil_2d_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2D class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(ParamOperation):\n",
    "\n",
    "    def __init__(self, \n",
    "                 param: Tensor):\n",
    "        super().__init__(param)\n",
    "        self.param_size = param.shape[0]\n",
    "        self.param_pad = self.param_size // 2\n",
    "        \n",
    "    def _pad_1d_obs(self, obs: Tensor) -> Tensor:\n",
    "        z = torch.Tensor([0])\n",
    "        z = z.repeat(self.param_pad)\n",
    "        return torch.cat([z, obs, z])\n",
    "\n",
    "    def _pad_1d(self, inp: Tensor) -> Tensor:\n",
    "        outs = [self._pad_1d_obs(obs) for obs in inp]\n",
    "        return torch.stack(outs)\n",
    "        \n",
    "    def _pad_2d_obs(self,\n",
    "                    inp: Tensor):\n",
    "\n",
    "        inp_pad = self._pad_1d_batch(inp, self.param_pad)\n",
    "        other = torch.zeros(num, inp.shape[0] + num * 2)\n",
    "        return torch.cat([other, inp_pad, other])\n",
    "\n",
    "    def _pad_2d(self, inp: Tensor):\n",
    "        \n",
    "        outs = [_pad_2d_obs(obs, num) for obs in inp]\n",
    "        return torch.stack(outs)\n",
    "\n",
    "    def _compute_output_obs(self, \n",
    "                            obs: Tensor):\n",
    "        '''\n",
    "        Obs is a 2d square Tensor, so is param\n",
    "        '''\n",
    "        obs_pad = self._pad_2d_obs(obs)\n",
    "\n",
    "        out = torch.zeros(obs.shape)\n",
    "\n",
    "        for o_w in range(out.shape[0]):\n",
    "            for o_h in range(out.shape[1]):\n",
    "                for p_w in range(self.param_size):\n",
    "                    for p_h in range(self.param_size):\n",
    "                        out[o_w][o_h] += self.param_size[p_w][p_h] * obs_pad[o_w+p_w][o_h+p_h]\n",
    "        return out    \n",
    "\n",
    "    def _compute_output(self):\n",
    "\n",
    "        outs = [self._compute_output_obs(obs) for obs in self.input_]\n",
    "        return torch.stack(outs)\n",
    "\n",
    "    def _compute_grads_obs(self, \n",
    "                           input_obs: Tensor,\n",
    "                           output_grad_obs: Tensor) -> Tensor:\n",
    "\n",
    "        output_obs_pad = self._pad_2d_obs(output_grad_obs)\n",
    "        input_grad = torch.zeros_like(input_obs)\n",
    "\n",
    "        for i_w in range(input_obs.shape[0]):\n",
    "            for i_h in range(input_obs.shape[1]):\n",
    "                for p_w in range(param_size):\n",
    "                    for p_h in range(param_size):\n",
    "                        input_grad[i_w][i_h] += output_obs_pad[i_w+self.param_size-p_w-1][i_h+self.param_size-p_h-1] \\\n",
    "                        * self.param[p_w][p_h]\n",
    "\n",
    "        return input_grad\n",
    "\n",
    "    def _compute_grads(self, output_grad: Tensor) -> Tensor:\n",
    "\n",
    "        grads = [_compute_grads_obs(self.input_[i], output_grad[i], self.param) for i in range(output_grad.shape[0])]    \n",
    "\n",
    "        return torch.stack(grads)\n",
    "\n",
    "\n",
    "    def _param_grad(inp: Tensor,\n",
    "                    output_grad: Tensor, \n",
    "                    param: Tensor) -> Tensor:\n",
    "\n",
    "        param_size = param.shape[0]\n",
    "        inp_pad = _pad_2d(inp, param_size // 2)\n",
    "\n",
    "        param_grad = torch.zeros_like(param)\n",
    "        img_shape = output_grad.shape[1:]\n",
    "\n",
    "        for i in range(inp.shape[0]):\n",
    "            for o_w in range(img_shape[0]):\n",
    "                for o_h in range(img_shape[1]):\n",
    "                    for p_w in range(param_size):\n",
    "                        for p_h in range(param_size):\n",
    "                            param_grad[p_w][p_h] += inp_pad[i][o_w+p_w][o_h+p_h] \\\n",
    "                            * output_grad[i][o_w][o_h]\n",
    "        return param_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "\n",
    "* Channels (another for loop)\n",
    "* `Flatten`\n",
    "* How to wrap this in a layer - with activation, same as Dense\n",
    "* Figure out how to write `for` loops in Cython\n",
    "\n",
    "MNIST demo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
