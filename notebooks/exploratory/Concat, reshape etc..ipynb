{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Lincoln to system path\n",
    "import sys\n",
    "sys.path.append(\"/Users/seth/development/lincoln/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lincoln.operations import Operation, ParamOperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Size((28, 28, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil1 = Tensor([[1,1,1], [2,2,2]])\n",
    "fil1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(Operation):\n",
    "    def __init__(self, shape: Tuple):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "\n",
    "    def _output(self) -> Tensor:\n",
    "        return self.input.view(self.shape)\n",
    "\n",
    "\n",
    "    def _input_grad(self, output_grad: Tensor) -> Tensor:\n",
    "        return output_grad.view(self.input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10218)\n",
    "inp = Tensor(5, 1, 28, 28).uniform_(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Reshape((5*1*28*28,))\n",
    "out = r.forward(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1648)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_grad = torch.ones_like(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 28, 28])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.backward(out_grad).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common instance of concat: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat will be used within a layer. A layer will take in one input, output one output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `LSTM Layer` \n",
    "\n",
    "Input: series of word embeddings, cell state.\n",
    "\n",
    "Output: series of embeddings of the same size as the word, hidden state.\n",
    "\n",
    "Cell state will be an attribute of the layer.\n",
    "\n",
    "LSTM layer will have an additional function \"reset state\" that resets the hidden state to zero.\n",
    "\n",
    "## `LSTM Node` \n",
    "\n",
    "Each LSTM layer will have a series of a special kind of operation, `LSTM Node`. These nodes will have a series of special operations: they will take in as input an embedding and a hidden state and pass out an embedding and an updated hidden state. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations of LSTM Node:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Receives as input:\n",
    "\n",
    "* X (batch size x embedding dim)\n",
    "* H_prev (batch size x hidden dim)\n",
    "* C_prev (batch size x hidden dim)\n",
    "\n",
    "1. Z = Concat(X, H)\n",
    "1. Z1, Z2, Z3, Z4 = Copy(Z)\n",
    "1. F = WeightMultiply(Z1, W_f)\n",
    "1. F = BiasAdd(F, B_f)\n",
    "1. F_out = Sigmoid(F)\n",
    "1. I = WeightMultiply(Z2, W_i)\n",
    "1. I = BiasAdd(I, B_i)\n",
    "1. I_out = Sigmoid(I)\n",
    "1. C = WeightMultiply(Z3, W_c)\n",
    "1. C = BiasAdd(C, B_c)\n",
    "1. C_bar = Tanh(C, B_c)\n",
    "1. C1 = Multiply(F_out, C_prev)\n",
    "1. C2 = Multiply(I_out, C_bar)\n",
    "1. C_new = Add(C1, C2)\n",
    "1. O = WeightMutiply(Z4, W_o)\n",
    "1. O = Add(O, B_o)\n",
    "1. O_out = Sigmoid(O)\n",
    "1. C_tan = Tanh(C_new)\n",
    "1. H_new = Multiply(O_out, C_tan)\n",
    "1. H_out = WeightMultiply(H_new, W_v)\n",
    "1. X_out = BiasAdd(H_out, B_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues:\n",
    "\n",
    "* Concat operations needs to produce four distinct outputs. \n",
    "    * Potential solution: `Copy` operation that sums gradients.\n",
    "\n",
    "* Need a way to handle branching:\n",
    "* After `Copy`, there will be four `forward` operations happening.\n",
    "* Can't write `for operation in self.operations: operation.forward(X)`\n",
    "    * Maybe I can\n",
    "    \n",
    "* What about weights?\n",
    "* Previously: initialize weights for each operation via `self.param`.\n",
    "* Now: initialize weights via, if the Operation is `LSTMNode`:\n",
    "    * `LSTMNode.params = []` and append appropriate weights.\n",
    "* What about the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operation(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def forward(self, input: Tensor):\n",
    "\n",
    "        self.input = input\n",
    "\n",
    "        self.output = self._output()\n",
    "\n",
    "        return self.output\n",
    "\n",
    "\n",
    "    def backward(self, output_grad: Tensor) -> Tensor:\n",
    "\n",
    "        assert_same_shape(self.output, output_grad)\n",
    "\n",
    "        self._compute_grads(output_grad)\n",
    "\n",
    "        assert_same_shape(self.input, self.input_grad)\n",
    "        return self.input_grad\n",
    "\n",
    "\n",
    "    def _compute_grads(self, output_grad: Tensor) -> Tensor:\n",
    "\n",
    "        self.input_grad = self._input_grad(output_grad)\n",
    "\n",
    "        assert_same_shape(self.input, self.input_grad)\n",
    "        return self.input_grad\n",
    "\n",
    "    def _output(self) -> Tensor:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def _input_grad(self, output_grad: Tensor) -> Tensor:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "Z, Z = Concat(X, H_in) # Concat takes in two inputs produces one output, will have X_grad and H_in_grad\n",
    "\n",
    "Z_1, Z_2, Z_3 = Copy(Z, 3)\n",
    "\n",
    "F = WeightMultiply(Z_1, W_f) \n",
    "F = BiasAdd(F, B_f)\n",
    "F_out = Sigmoid(F)\n",
    "\n",
    "I = WeightMultiply(Z_2, W_i) \n",
    "I = BiasAdd(I, B_i)\n",
    "I_out = Sigmoid(I)\n",
    "\n",
    "C = WeightMultiply(Z_3, W_c)\n",
    "C = BiasAdd(C, B_c)\n",
    "C_bar = Tanh(C)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations are the smallest units that have inputs and outputs defined by having a input and output.\n",
    "\n",
    "Going to need to build operations that:\n",
    "\n",
    "* Can take in one input and produce multiple outputs\n",
    "* If it produces multiple outputs, _gradients will need to accumulate_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
