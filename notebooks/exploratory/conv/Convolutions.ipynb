{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Lincoln to system path\n",
    "import sys\n",
    "sys.path.append(\"/Users/seth/development/lincoln/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "\n",
    "import typing\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lincoln.operations import Operation, ParamOperation\n",
    "from lincoln.layers import Layer\n",
    "from lincoln.activations import Activation, LinearAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    '''\n",
    "    Once we define all the Operations and the outline of a layer, all that remains to implement here \n",
    "    is the _setup_layer function!\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 neurons: int, \n",
    "                 activation: Activation = LinearAct) -> None:\n",
    "        super().__init__(neurons)\n",
    "        self.activation = activation\n",
    "\n",
    "    def _setup_layer(self, num_in: int) -> None:\n",
    "        # weights\n",
    "        self.params.append(torch.empty(num_in, self.neurons).uniform_(-1, 1))\n",
    "        \n",
    "        # bias\n",
    "        self.params.append(torch.empty(1, self.neurons).uniform_(-1, 1))\n",
    "        \n",
    "        self.operations = [WeightMultiply(self.params[0]), \n",
    "                           BiasAdd(self.params[1])] + [self.activation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightMultiply(ParamOperation):\n",
    "\n",
    "    def __init__(self, W: Tensor):\n",
    "        super().__init__(W)\n",
    "\n",
    "\n",
    "    def _output(self) -> Tensor:\n",
    "        return torch.mm(self.input, self.param)\n",
    "\n",
    "\n",
    "    def _input_grad(self, output_grad: Tensor) -> Tensor:\n",
    "        return torch.mm(output_grad, self.param.transpose(0, 1))\n",
    "\n",
    "\n",
    "    def _param_grad(self, output_grad: Tensor) -> Tensor:\n",
    "        return torch.mm(self.input.transpose(0, 1), output_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_same_shape(output: Tensor, \n",
    "                      output_grad: Tensor):\n",
    "    assert output.shape == output_grad.shape, \\\n",
    "    '''\n",
    "    Two tensors should have the same shape; instead, first Tensor's shape is {0}\n",
    "    and second Tensor's shape is {1}.\n",
    "    '''.format(tuple(output_grad.shape), tuple(output.shape))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_dim(t: Tensor,\n",
    "               dim: Tensor):\n",
    "    assert len(t.shape) == dim, \\\n",
    "    '''\n",
    "    Tensor expected to have dimension {0}, instead has dimension {1}\n",
    "    '''.format(dim, len(t.shape))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 input, 1 output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_1d(inp: Tensor,\n",
    "            num: int) -> Tensor:\n",
    "    z = torch.Tensor([0])\n",
    "    z = z.repeat(num)\n",
    "    return torch.cat([z, inp, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_1d(inp: Tensor, \n",
    "            fil: Tensor) -> Tensor:\n",
    "    \n",
    "    # assert correct dimensions\n",
    "    assert_dim(inp, 1)\n",
    "    assert_dim(fil, 1)\n",
    "    \n",
    "    # pad the input\n",
    "    fil_len = fil.shape[0]\n",
    "    fil_mid = fil_len // 2\n",
    "    inp_pad = _pad_1d(inp, fil_mid)\n",
    "    \n",
    "    # initialize the output\n",
    "    out = torch.zeros(inp.shape)\n",
    "    \n",
    "    # perform the 1d convolution\n",
    "    for o in range(out.shape[0]):\n",
    "        for f in range(fil_len):\n",
    "            out[o] += fil[f] * inp_pad[o+f]\n",
    "\n",
    "    # ensure shapes didn't change            \n",
    "    assert_same_shape(inp, out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = Tensor([1,2,3,4,5])\n",
    "fil1 = Tensor([1,1,1])\n",
    "fil1_0 = Tensor([2,1,1])\n",
    "fil1_1 = Tensor([1,2,1])\n",
    "fil1_2 = Tensor([1,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_1d_sum(inp: Tensor, \n",
    "                fil: Tensor) -> Tensor:\n",
    "    out = conv_1d(inp, fil)\n",
    "    return torch.sum(out).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_sum(inp1, fil1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "15.0\n",
      "14.0\n"
     ]
    }
   ],
   "source": [
    "print(conv_1d_sum(inp1, fil1_0) - conv_1d_sum(inp1, fil1))\n",
    "print(conv_1d_sum(inp1, fil1_1) - conv_1d_sum(inp1, fil1))\n",
    "print(conv_1d_sum(inp1, fil1_2) - conv_1d_sum(inp1, fil1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_1d_sum(inp: Tensor, \n",
    "                fil: Tensor) -> Tensor:\n",
    "    out = conv_1d(inp, fil)\n",
    "    return torch.sum(out).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(92318)\n",
    "random.randint(0, inp1.shape[0])\n",
    "random.randint(0, fil1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1_4 = Tensor([1,2,3,4,6])\n",
    "fil1 = Tensor([1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_sum(inp1, fil1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_sum(inp1_4, fil1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = Tensor([1,2,3,4,5])\n",
    "fil1_0 = Tensor([2,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_sum(inp1, fil1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_sum(inp1, fil1_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _param_grad(inp: Tensor, \n",
    "                fil: Tensor, \n",
    "                output_grad: Tensor = None) -> Tensor:\n",
    "    \n",
    "    fil_len = fil.shape[0]\n",
    "    fil_mid = fil_len // 2\n",
    "    inp_pad = _pad_1d(inp, fil_mid)\n",
    "    \n",
    "    if output_grad is None:\n",
    "        output_grad = torch.ones_like(inp)\n",
    "    else:\n",
    "        assert_same_shape(inp, output_grad)\n",
    "    \n",
    "    output_pad = _pad_1d(output_grad, fil_mid)\n",
    "    \n",
    "    # Zero padded 1 dimensional convolution\n",
    "    param_grad = torch.zeros_like(fil)\n",
    "    input_grad = torch.zeros_like(inp)\n",
    "\n",
    "    for f in range(fil.shape[0]):\n",
    "        for o in range(inp.shape[0]):\n",
    "            param_grad[f] += inp_pad[o+f] * output_grad[o]\n",
    "            input_grad[o] += output_pad[o+fil_len-f-1] * fil[f]\n",
    "        \n",
    "    assert_same_shape(param_grad, fil)\n",
    "    assert_same_shape(input_grad, inp)\n",
    "    return param_grad, input_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _input_grad(inp: Tensor, \n",
    "                fil: Tensor, \n",
    "                output_grad: Tensor = None) -> Tensor:\n",
    "    \n",
    "    fil_len = fil.shape[0]\n",
    "    fil_mid = fil_len // 2\n",
    "    inp_pad = _pad_1d(inp, fil_mid)\n",
    "    \n",
    "    if output_grad is None:\n",
    "        output_grad = torch.ones_like(inp)\n",
    "    else:\n",
    "        assert_same_shape(inp, output_grad)\n",
    "    \n",
    "    output_pad = _pad_1d(output_grad, fil_mid)\n",
    "    \n",
    "    input_grad = torch.zeros_like(inp)\n",
    "\n",
    "    for f in range(fil.shape[0]):\n",
    "        for o in range(inp.shape[0]):\n",
    "            input_grad[o] += output_pad[o+fil_len-f-1] * fil[f]\n",
    "        \n",
    "    assert_same_shape(input_grad, inp)\n",
    "    return input_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_t = Tensor([0,1,2,3,4,5,6])\n",
    "fil_t = Tensor([1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_grad(inp: Tensor,\n",
    "                fil: Tensor):\n",
    "    \n",
    "    inp_grad_check = torch.zeros_like(inp)\n",
    "    fil_grad_check = torch.zeros_like(fil)\n",
    "\n",
    "    for i in range(inp.shape[0]):\n",
    "        inp_temp = inp.clone()\n",
    "        inp_temp[i] = inp_temp[i] + 1\n",
    "        sum1 = conv_1d_sum(inp, fil)\n",
    "        sum2 = conv_1d_sum(inp_temp, fil)\n",
    "        inp_grad_check[i] = sum2 - sum1\n",
    "\n",
    "    for f in range(fil.shape[0]):\n",
    "        fil_temp = fil.clone()\n",
    "        fil_temp[f] = fil_temp[f] + 1\n",
    "        sum1 = conv_1d_sum(inp, fil)\n",
    "        sum2 = conv_1d_sum(inp, fil_temp)\n",
    "        fil_grad_check[f] = sum2 - sum1\n",
    "        \n",
    "    return fil_grad_check, inp_grad_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([15., 21., 21.]), tensor([2., 3., 3., 3., 3., 3., 2.]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_param_grad(inp_t, fil_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([15., 21., 21.]), tensor([2., 3., 3., 3., 3., 3., 2.]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_check_grad(inp_t, fil_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_2 = Tensor([[0,1,2,3,4,5,6], \n",
    "                [1,2,3,4,5,6,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_1d(inp: Tensor,\n",
    "            num: int) -> Tensor:\n",
    "    z = torch.Tensor([0])\n",
    "    z = z.repeat(num)\n",
    "    return torch.cat([z, inp, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_1d_batch(inp: Tensor, \n",
    "                  num: int) -> Tensor:\n",
    "    outs = [_pad_1d(obs, num) for obs in inp]\n",
    "    return torch.stack(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 2., 3., 4., 5., 6., 0.],\n",
       "        [0., 1., 2., 3., 4., 5., 6., 7., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pad_1d_batch(inp_2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_1d_batch(inp: Tensor, \n",
    "                  fil: Tensor) -> Tensor:\n",
    "\n",
    "    outs = [conv_1d(obs, fil) for obs in inp]\n",
    "    return torch.stack(outs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  3.,  6.,  9., 12., 15., 11.],\n",
       "        [ 3.,  6.,  9., 12., 15., 18., 13.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_batch(inp_2, fil1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_1d_batch(inp: Tensor, \n",
    "                  fil: Tensor) -> Tensor:\n",
    "\n",
    "    out = conv_1d_batch(inp, fil)\n",
    "    \n",
    "    out_grad = torch.ones_like(out)\n",
    "    \n",
    "    batch_size = out_grad.shape[0]\n",
    "        \n",
    "    grads = [_input_grad(inp[i], fil, out_grad[i])[1] for i in range(batch_size)]    \n",
    "\n",
    "    return torch.stack(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_grad_1d_batch(inp: Tensor, \n",
    "                        fil: Tensor) -> Tensor:\n",
    "\n",
    "    output_grad = torch.ones_like(inp)\n",
    "    \n",
    "    inp_pad = _pad_1d_batch(inp, 1)\n",
    "    out_pad = _pad_1d_batch(inp, 1)\n",
    "\n",
    "    param_grad = torch.ones_like(fil)    \n",
    "    \n",
    "    for i in range(inp.shape[0]):\n",
    "        for p in range(fil.shape[0]):\n",
    "            for o in range(inp.shape[1]):\n",
    "                param_grad[p] += inp_pad[i][o+p] * output_grad[i][o]    \n",
    "    return param_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing conv + weight multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just `param_grad_1d_batch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_grad_1d_batch(inp: Tensor, \n",
    "                        fil: Tensor, \n",
    "                        output_grad: Tensor) -> Tensor:\n",
    "\n",
    "    inp_pad = _pad_1d_batch(inp, 1)\n",
    "    out_pad = _pad_1d_batch(inp, 1)\n",
    "    param_grad = torch.zeros_like(fil)    \n",
    "    \n",
    "    for i in range(inp.shape[0]):\n",
    "        for p in range(fil.shape[0]):\n",
    "            for o in range(inp.shape[1]):\n",
    "                param_grad[p] += inp_pad[i][o+p] * output_grad[i][o]    \n",
    "    return param_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_conv(inp: Tensor, \n",
    "                     fil: Tensor):\n",
    "    conv_out = conv_1d_batch(inp, fil)\n",
    "\n",
    "    return round(torch.sum(conv_out).item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4595, -0.0404,  0.7231,  0.9657,  0.9637, -0.6279,  0.7466],\n",
      "        [ 0.8894, -0.9637,  0.1816,  0.4596,  0.6427, -0.0797, -0.8224]])\n",
      "tensor([ 0.7842, -0.3495, -0.1091])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(83118)\n",
    "inp_t = Tensor(2, 7).uniform_(-1, 1)\n",
    "fil = Tensor(torch.empty(3).uniform_(-1, 1))\n",
    "print(inp_t)\n",
    "print(fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9457"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_conv(inp_t, fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_grad = torch.ones_like(inp_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.6545, 2.5786, 2.1487])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grad_1d_batch(inp_t, \n",
    "                    fil, \n",
    "                    output_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fil_grad[0] = 2.6545`\n",
    "\n",
    "Adding 0.1 to `fil[0]` should change the sum to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2111"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(0.9457 + 0.1 * 2.6545, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8842, -0.3495, -0.1091])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil2 = torch.clone(fil)\n",
    "fil2[0] += 0.1\n",
    "fil2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2112"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_conv(inp_t, fil2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking input gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3255, 0.3255])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_1d_batch(inp_2, fil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`inp_t[0][0]`'s gradient is `0.4346`. So increasing it by 0.1 should increase the sum to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9892"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(0.9457 + 0.1 * 0.4346, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3595, -0.0404,  0.7231,  0.9657,  0.9637, -0.6279,  0.7466],\n",
       "        [ 0.8894, -0.9637,  0.1816,  0.4596,  0.6427, -0.0797, -0.8224]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_t2 = inp_t.clone()\n",
    "inp_t2[0][0] += 0.1\n",
    "inp_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9892"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_conv(inp_t2, fil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With weight multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.8207"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_t = Tensor(2, 7).uniform_(-1, 1)\n",
    "fil = Tensor(torch.empty(3).uniform_(-1, 1))\n",
    "weights = Tensor(torch.empty(7, 5).uniform_(-1, 1))\n",
    "\n",
    "conv_out = conv_1d_batch(inp_t, fil)\n",
    "\n",
    "out = torch.mm(conv_out, weights)\n",
    "\n",
    "round(torch.sum(out).item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4404,  0.2923, -0.1474])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_grad = torch.mm(torch.ones_like(out), weights.transpose(0, 1))\n",
    "\n",
    "fil_grad = param_grad_1d_batch(inp_t, fil, out_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7563, 1.8538, 7.7927])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fil_grad[0] = 2.7563`\n",
    "\n",
    "Adding 0.1 to `FIL[0]` should change the sum to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5451"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(-1.8207 + 0.1 * 2.7563, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_conv_mul(inp: Tensor, \n",
    "                     fil: Tensor, \n",
    "                     weights: Tensor):\n",
    "    conv_out = conv_1d_batch(inp_t, fil)\n",
    "\n",
    "    out = torch.mm(conv_out, weights)\n",
    "\n",
    "    return round(torch.sum(out).item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3404,  0.2923, -0.1474])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil2 = torch.clone(fil)\n",
    "fil2[0] += 0.1\n",
    "fil2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.545"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_conv_mul(inp_t, fil2, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operation(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def forward(self, input_: Tensor):\n",
    "        self.input_ = input_\n",
    "\n",
    "        self.output = self._output()\n",
    "\n",
    "        return self.output\n",
    "\n",
    "\n",
    "    def backward(self, output_grad: Tensor) -> Tensor:\n",
    "\n",
    "        assert_same_shape(self.output, output_grad)\n",
    "\n",
    "        self._compute_grads(output_grad)\n",
    "\n",
    "        assert_same_shape(self.input_, self.input_grad)\n",
    "        return self.input_grad\n",
    "\n",
    "\n",
    "    def _compute_grads(self, output_grad: Tensor) -> Tensor:\n",
    "        self.input_grad = self._input_grad(output_grad)\n",
    "\n",
    "\n",
    "    def _output(self) -> Tensor:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "    def _input_grad(self, output_grad: Tensor) -> Tensor:\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "\n",
    "class ParamOperation(Operation):\n",
    "\n",
    "    def __init__(self, param: Tensor) -> Tensor:\n",
    "        super().__init__()\n",
    "        self.param = param\n",
    "\n",
    "\n",
    "    def _compute_grads(self, output_grad: Tensor) -> Tensor:\n",
    "        self.input_grad = self._input_grad(output_grad)\n",
    "        self.param_grad = self._param_grad(output_grad)\n",
    "\n",
    "\n",
    "    def _param_grad(self, output_grad: Tensor) -> Tensor:\n",
    "        raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1D(ParamOperation):\n",
    "\n",
    "    def __init__(self, \n",
    "                 param: Tensor):\n",
    "        super().__init__(param)\n",
    "        self.param_size = param.shape[0]\n",
    "        self.param_pad = self.param_size // 2\n",
    "        \n",
    "    def _pad_1d_obs(self, obs: Tensor) -> Tensor:\n",
    "        z = torch.Tensor([0])\n",
    "        z = z.repeat(self.param_pad)\n",
    "        return torch.cat([z, obs, z])\n",
    "\n",
    "    def _pad_1d(self, inp: Tensor) -> Tensor:\n",
    "        outs = [self._pad_1d_obs(obs) for obs in inp]\n",
    "        return torch.stack(outs)    \n",
    "\n",
    "    def _compute_output_obs(self, obs: Tensor):\n",
    "        \n",
    "        obs_pad = self._pad_1d_obs(obs)\n",
    "\n",
    "        out = torch.zeros(obs.shape)\n",
    "\n",
    "        for o in range(out.shape[0]):\n",
    "            for p in range(self.param_size):\n",
    "                out[o] += self.param[p] * obs_pad[o+p]\n",
    "        return out\n",
    "    \n",
    "    def _output(self):\n",
    "        \n",
    "        outs = [self._compute_output_obs(obs) for obs in self.input_]\n",
    "        return torch.stack(outs)\n",
    "    \n",
    "    def _compute_grads_obs(self, \n",
    "                           input_obs: Tensor,\n",
    "                           output_grad_obs: Tensor) -> None:\n",
    "\n",
    "        output_obs_pad = self._pad_1d_obs(output_grad_obs)\n",
    "        input_obs_pad = self._pad_1d_obs(input_obs)\n",
    "        input_grad = torch.zeros_like(input_obs)\n",
    "\n",
    "        for p in range(self.param.shape[0]):\n",
    "            for o in range(input_obs.shape[0]):\n",
    "                input_grad[o] += output_obs_pad[o+self.param_size-p-1] * self.param[p]\n",
    "                \n",
    "        return input_grad\n",
    "        \n",
    "    def _input_grad(self, output_grad: Tensor) -> None:\n",
    "        \n",
    "        grads = [self._compute_grads_obs(self.input_[i], output_grad[i]) for i in range(output_grad.shape[0])]    \n",
    "\n",
    "        return torch.stack(grads)\n",
    "\n",
    "    def _param_grad(self, output_grad: Tensor) -> Tensor:\n",
    "\n",
    "        inp_pad = self._pad_1d(self.input_)\n",
    "        out_pad = self._pad_1d(output_grad)\n",
    "\n",
    "        param_grad = torch.zeros_like(self.param)\n",
    "\n",
    "        for i in range(self.input_.shape[0]):\n",
    "            for p in range(self.param.shape[0]):\n",
    "                for o in range(self.input_.shape[1]):\n",
    "                    param_grad[p] += inp_pad[i][o+p] * output_grad[i][o]\n",
    "        \n",
    "        return param_grad\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4404,  0.2923, -0.1474])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1779,  0.6374, -0.8940, -0.3311, -0.0193],\n",
       "        [-0.1690,  0.0073,  0.8437,  0.9426,  0.6066],\n",
       "        [ 0.4668,  0.5077, -0.6763,  0.0992, -0.4717],\n",
       "        [ 0.0476, -0.3656,  0.7781, -0.5844,  0.8515],\n",
       "        [ 0.8489,  0.6374,  0.6090,  0.6846,  0.5798],\n",
       "        [-0.6807,  0.3116, -0.1502, -0.3789, -0.1404],\n",
       "        [ 0.4816,  0.8886,  0.8650, -0.4064, -0.2798]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestConv(Layer):\n",
    "    '''\n",
    "    Once we define all the Operations and the outline of a layer, all that remains to implement here \n",
    "    is the _setup_layer function!\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 neurons: int, \n",
    "                 activation: Activation = LinearAct,\n",
    "                 filter_size: int = 3) -> None:\n",
    "        super().__init__(neurons)\n",
    "        self.activation = activation\n",
    "        self.filter_size = filter_size\n",
    "        \n",
    "\n",
    "    def _setup_layer(self, num_in: int) -> None:\n",
    "        # filter\n",
    "        self.params.append(Tensor([-0.4404,  0.2923, -0.1474]))\n",
    "        \n",
    "        # Weights\n",
    "        self.params.append(Tensor([[ 0.1779,  0.6374, -0.8940, -0.3311, -0.0193],\n",
    "        [-0.1690,  0.0073,  0.8437,  0.9426,  0.6066],\n",
    "        [ 0.4668,  0.5077, -0.6763,  0.0992, -0.4717],\n",
    "        [ 0.0476, -0.3656,  0.7781, -0.5844,  0.8515],\n",
    "        [ 0.8489,  0.6374,  0.6090,  0.6846,  0.5798],\n",
    "        [-0.6807,  0.3116, -0.1502, -0.3789, -0.1404],\n",
    "        [ 0.4816,  0.8886,  0.8650, -0.4064, -0.2798]]))\n",
    "        \n",
    "        self.operations = [Conv1D(self.params[0]),\n",
    "                           WeightMultiply(self.params[1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TestConv(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3163, -0.1501,  0.7113,  0.3191,  0.6163,  0.7247, -0.0049],\n",
       "        [-0.1855,  0.7793,  0.8862, -0.1635, -0.4434,  0.8358,  0.8314]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0912, -0.1621, -0.6499,  0.3251, -0.3171],\n",
       "        [-0.5356, -0.1283, -0.2132,  0.2433, -0.2916]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = a.forward(Tensor(inp_t))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.8206"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(a.forward(Tensor(inp_t)).sum().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1080,  0.7482, -0.6709, -1.2561,  1.3323, -1.4810,  0.6059],\n",
       "        [-1.1080,  0.7482, -0.6709, -1.2561,  1.3323, -1.4810,  0.6059]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.backward(torch.ones_like(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7561, 1.8538, 7.7929])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a._param_grads()\n",
    "\n",
    "a.operations[0].param_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tensor([2.7563, 1.8538, 7.7927])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks out! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist_trainset = MNIST(root=\"./data\", train=True, download=False, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = mnist_trainset.train_data.type(torch.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_imgs = mnist_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pad = 2\n",
    "obs = np.zeros(28)\n",
    "a = np.zeros(pad)\n",
    "np.concatenate([a, obs, a]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4100, -0.6319,  0.7821],\n",
       "        [ 0.9452,  0.9196, -0.1515],\n",
       "        [-0.3346,  0.3960,  0.7145]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(90118)\n",
    "fil = Tensor(torch.empty(3, 3).uniform_(-1, 1))\n",
    "fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_imgs = mnist_data[:2]\n",
    "mnist_img = mnist_imgs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_2d_obs(inp: Tensor, \n",
    "                num: int):\n",
    "    '''\n",
    "    Input is a 2 dimensional, square, 2D Tensor\n",
    "    '''\n",
    "    \n",
    "    inp_pad = _pad_1d_batch(inp, num)\n",
    "    other = torch.zeros(num, inp.shape[0] + num * 2)\n",
    "    return torch.cat([other, inp_pad, other])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_1d_batch(inp: Tensor, \n",
    "                  num: int) -> Tensor:\n",
    "#     import pdb; pdb.set_trace()\n",
    "    outs = [_pad_1d(obs, num) for obs in inp]\n",
    "\n",
    "    return torch.stack(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_1d(inp: Tensor,\n",
    "            num: int) -> Tensor:\n",
    "    z = torch.Tensor([0])\n",
    "    z = z.repeat(num)\n",
    "#     import pdb; pdb.set_trace()\n",
    "    return torch.cat([z, inp, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_img[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 30])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pad_2d_obs(mnist_img, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_2d(inp: Tensor, \n",
    "            num: int):\n",
    "    '''\n",
    "    Input is a 3 dimensional tensor, first dimension batch size\n",
    "    '''\n",
    "\n",
    "    outs = [_pad_2d_obs(obs, num) for obs in inp]\n",
    "    return torch.stack(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30, 30])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pad_2d(mnist_imgs, 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1D**:\n",
    "\n",
    "```python\n",
    "    def _compute_output_obs(self, obs: Tensor):\n",
    "        \n",
    "        obs_pad = self._pad_1d_obs(obs)\n",
    "\n",
    "        out = torch.zeros(obs.shape)\n",
    "\n",
    "        for o in range(out.shape[0]):\n",
    "            for p in range(self.param_size):\n",
    "                out[o] += self.param[p] * obs_pad[o+p]\n",
    "        return out\n",
    "    \n",
    "    def _compute_output(self):\n",
    "        \n",
    "        outs = [self._compute_output_obs(obs) for obs in self.input_]\n",
    "        return torch.stack(outs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_output_obs_2d(obs: Tensor, \n",
    "                           param: Tensor):\n",
    "    '''\n",
    "    Obs is a 2d square Tensor, so is param\n",
    "    '''\n",
    "    param_mid = param.shape[0] // 2\n",
    "    \n",
    "    obs_pad = _pad_2d_obs(obs, param_mid)\n",
    "    \n",
    "    out = torch.zeros(obs.shape)\n",
    "    \n",
    "    for o_w in range(out.shape[0]):\n",
    "        for o_h in range(out.shape[1]):\n",
    "            for p_w in range(param.shape[0]):\n",
    "                for p_h in range(param.shape[1]):\n",
    "                    out[o_w][o_h] += param[p_w][p_h] * obs_pad[o_w+p_w][o_h+p_h]\n",
    "    return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_compute_output_obs_2d(mnist_imgs[0], fil).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_compute_output_obs_2d(torch.ones_like(mnist_imgs[0]), \n",
    "                   torch.ones_like(fil)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_output_2d(img_batch: Tensor,\n",
    "                       param: Tensor):\n",
    "    \n",
    "    outs = [_compute_output_obs_2d(obs, param) for obs in img_batch]\n",
    "    return torch.stack(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 28, 28])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_compute_output_2d(mnist_imgs, fil).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Param grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "def _compute_grads_obs(self, \n",
    "                       input_obs: Tensor,\n",
    "                       output_grad_obs: Tensor) -> None:\n",
    "\n",
    "    output_obs_pad = self._pad_1d_obs(output_grad_obs)\n",
    "    input_obs_pad = self._pad_1d_obs(input_obs)\n",
    "    input_grad = torch.zeros_like(input_obs)\n",
    "\n",
    "    for p in range(self.param.shape[0]):\n",
    "        for o in range(input_obs.shape[0]):\n",
    "            input_grad[o] += output_obs_pad[o+self.param_size-p-1] * self.param[p]\n",
    "\n",
    "    return input_grad\n",
    "\n",
    "def _compute_grads(self, output_grad: Tensor) -> None:\n",
    "\n",
    "    grads = [self._compute_grads_obs(self.input_[i], output_grad[i]) for i in range(output_grad.shape[0])]    \n",
    "\n",
    "    return torch.stack(grads)\n",
    "\n",
    "def _param_grad(self, output_grad: Tensor) -> Tensor:\n",
    "\n",
    "    inp_pad = self._pad_1d(self.input_)\n",
    "    out_pad = self._pad_1d(output_grad)\n",
    "\n",
    "    param_grad = torch.zeros_like(self.param)\n",
    "\n",
    "    for i in range(self.input_.shape[0]):\n",
    "        for p in range(self.param.shape[0]):\n",
    "            for o in range(self.input_.shape[1]):\n",
    "                param_grad[p] += inp_pad[i][o+p] * output_grad[i][o]\n",
    "\n",
    "    return param_grad\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_grads_obs_2d(input_obs: Tensor,\n",
    "                          output_grad_obs: Tensor, \n",
    "                          param: Tensor) -> Tensor:\n",
    "    '''\n",
    "    input_obs: 2D Tensor representing the input observation\n",
    "    output_grad_obs: 2D Tensor representing the output gradient  \n",
    "    param: 2D filter\n",
    "    '''\n",
    "    \n",
    "    param_size = param.shape[0]\n",
    "    output_obs_pad = _pad_2d_obs(output_grad_obs, param_size // 2)\n",
    "    input_grad = torch.zeros_like(input_obs)\n",
    "    \n",
    "    for i_w in range(input_obs.shape[0]):\n",
    "        for i_h in range(input_obs.shape[1]):\n",
    "            for p_w in range(param_size):\n",
    "                for p_h in range(param_size):\n",
    "                    input_grad[i_w][i_h] += output_obs_pad[i_w+param_size-p_w-1][i_h+param_size-p_h-1] \\\n",
    "                    * param[p_w][p_h]\n",
    "\n",
    "    return input_grad\n",
    "\n",
    "def _compute_grads_2d(inp: Tensor,\n",
    "                      output_grad: Tensor, \n",
    "                      param: Tensor) -> Tensor:\n",
    "\n",
    "    grads = [_compute_grads_obs_2d(inp[i], output_grad[i], param) for i in range(output_grad.shape[0])]    \n",
    "\n",
    "    return torch.stack(grads)\n",
    "\n",
    "\n",
    "def _param_grad_2d(inp: Tensor,\n",
    "                output_grad: Tensor, \n",
    "                param: Tensor) -> Tensor:\n",
    "\n",
    "    param_size = param.shape[0]\n",
    "    inp_pad = _pad_2d(inp, param_size // 2)\n",
    "\n",
    "    param_grad = torch.zeros_like(param)\n",
    "    img_shape = output_grad.shape[1:]\n",
    "    \n",
    "    for i in range(inp.shape[0]):\n",
    "        for o_w in range(img_shape[0]):\n",
    "            for o_h in range(img_shape[1]):\n",
    "                for p_w in range(param_size):\n",
    "                    for p_h in range(param_size):\n",
    "                        param_grad[p_w][p_h] += inp_pad[i][o_w+p_w][o_h+p_h] \\\n",
    "                        * output_grad[i][o_w][o_h]\n",
    "    return param_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_grads = _compute_grads_2d(mnist_imgs, \n",
    "                  torch.ones_like(mnist_imgs),\n",
    "                  fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 28, 28])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_param_grad_2d(mnist_imgs, \n",
    "               torch.ones_like(mnist_imgs),\n",
    "               fil).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1458., 1512., 1458.],\n",
       "        [1512., 1568., 1512.],\n",
       "        [1458., 1512., 1458.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_param_grad_2d(torch.ones_like(mnist_imgs), \n",
    "            torch.ones_like(mnist_imgs),\n",
    "            torch.ones_like(fil))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4595, -0.0404,  0.7231,  ...,  0.7793,  0.8862, -0.1635],\n",
      "         [-0.4434,  0.8358,  0.8314,  ...,  0.8515,  0.8489,  0.6374],\n",
      "         [ 0.6090,  0.6846,  0.5798,  ..., -0.9869, -0.5122,  0.1004],\n",
      "         ...,\n",
      "         [-0.6893,  0.6844,  0.3930,  ...,  0.8784, -0.9622,  0.6246],\n",
      "         [ 0.2483,  0.2489,  0.6214,  ..., -0.4182,  0.3494, -0.3749],\n",
      "         [-0.0431, -0.5983,  0.0159,  ...,  0.9402, -0.7548, -0.0260]],\n",
      "\n",
      "        [[-0.9996, -0.0940, -0.2361,  ..., -0.8060,  0.2113,  0.2238],\n",
      "         [ 0.8753, -0.0206,  0.7403,  ...,  0.0474, -0.1131, -0.9616],\n",
      "         [ 0.9618, -0.7869, -0.1776,  ..., -0.2627,  0.0214,  0.1699],\n",
      "         ...,\n",
      "         [-0.7987,  0.2323,  0.5628,  ..., -0.3837,  0.3447,  0.7020],\n",
      "         [ 0.1002,  0.5694, -0.3786,  ...,  0.0969, -0.9385, -0.9083],\n",
      "         [-0.4816, -0.8912, -0.8171,  ...,  0.9857,  0.5978,  0.6349]]])\n",
      "tensor([[-0.4692,  0.8415, -0.3125],\n",
      "        [-0.4369, -0.4208,  0.9089],\n",
      "        [-0.5128,  0.0941,  0.4598]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(83118)\n",
    "inp_2d = Tensor(2, 28, 28).uniform_(-1, 1)\n",
    "fil_2d = Tensor(torch.empty(3, 3).uniform_(-1, 1))\n",
    "print(inp_2d)\n",
    "print(fil_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = _compute_output_2d(inp_2d, fil_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.3893)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_grad_2d = torch.ones_like(inp_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing input gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_grads_2d = _compute_grads_2d(inp_2d, out_grad_2d, fil_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1522)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_grads_2d[1][1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`inp_grads_2d[1][1][1] = 0.1522` That means if we increase `inp_2d[1][1][1]` by 0.1, the sum will increase to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4045"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(4.3893 + 0.1 * 0.1522, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_2d_sum(inp: Tensor, \n",
    "                fil: Tensor):\n",
    "    out = _compute_output_2d(inp, fil)\n",
    "    return torch.sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4595, -0.0404,  0.7231,  ...,  0.7793,  0.8862, -0.1635],\n",
       "         [-0.4434,  0.8358,  0.8314,  ...,  0.8515,  0.8489,  0.6374],\n",
       "         [ 0.6090,  0.6846,  0.5798,  ..., -0.9869, -0.5122,  0.1004],\n",
       "         ...,\n",
       "         [-0.6893,  0.6844,  0.3930,  ...,  0.8784, -0.9622,  0.6246],\n",
       "         [ 0.2483,  0.2489,  0.6214,  ..., -0.4182,  0.3494, -0.3749],\n",
       "         [-0.0431, -0.5983,  0.0159,  ...,  0.9402, -0.7548, -0.0260]],\n",
       "\n",
       "        [[-0.9996, -0.0940, -0.2361,  ..., -0.8060,  0.2113,  0.2238],\n",
       "         [ 0.8753,  0.0794,  0.7403,  ...,  0.0474, -0.1131, -0.9616],\n",
       "         [ 0.9618, -0.7869, -0.1776,  ..., -0.2627,  0.0214,  0.1699],\n",
       "         ...,\n",
       "         [-0.7987,  0.2323,  0.5628,  ..., -0.3837,  0.3447,  0.7020],\n",
       "         [ 0.1002,  0.5694, -0.3786,  ...,  0.0969, -0.9385, -0.9083],\n",
       "         [-0.4816, -0.8912, -0.8171,  ...,  0.9857,  0.5978,  0.6349]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_2d_2 = inp_2d.clone()\n",
    "inp_2d_2[1][1][1] += 0.1\n",
    "inp_2d_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3893)\n",
      "tensor(4.4045)\n"
     ]
    }
   ],
   "source": [
    "print(conv_2d_sum(inp_2d, fil_2d))\n",
    "print(conv_2d_sum(inp_2d_2, fil_2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing param gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12.9452, 11.3265, 15.7122],\n",
       "        [10.9300,  9.9202, 14.8306],\n",
       "        [ 7.7102,  6.6400, 10.0913]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grads_2d = _param_grad_2d(inp_2d, out_grad_2d, fil)\n",
    "param_grads_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`param_grads_2d[1][1] = 9.9202` That means if we increase `param_grads_2d[1][1]` by 0.1, the sum will increase to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.3813"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(4.3893 + 9.9202 * 0.1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4692,  0.8415, -0.3125],\n",
       "        [-0.4369, -0.3208,  0.9089],\n",
       "        [-0.5128,  0.0941,  0.4598]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil_2d_2 = fil_2d.clone()\n",
    "fil_2d_2[1][1] += 0.1\n",
    "fil_2d_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3893)\n",
      "tensor(5.3813)\n"
     ]
    }
   ],
   "source": [
    "print(conv_2d_sum(inp_2d, fil_2d))\n",
    "print(conv_2d_sum(inp_2d, fil_2d_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2D class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(ParamOperation):\n",
    "\n",
    "    def __init__(self, \n",
    "                 param: Tensor):\n",
    "        super().__init__(param)\n",
    "        self.param_size = param.shape[0]\n",
    "        self.param_pad = self.param_size // 2\n",
    "        \n",
    "    def _pad_1d_obs(self, obs: Tensor) -> Tensor:\n",
    "        z = torch.Tensor([0])\n",
    "        z = z.repeat(self.param_pad)\n",
    "        return torch.cat([z, obs, z])\n",
    "\n",
    "    def _pad_1d(self, inp: Tensor) -> Tensor:\n",
    "        outs = [self._pad_1d_obs(obs) for obs in inp]\n",
    "        return torch.stack(outs)\n",
    "        \n",
    "    def _pad_2d_obs(self,\n",
    "                    inp: Tensor):\n",
    "\n",
    "        inp_pad = self._pad_1d_batch(inp, self.param_pad)\n",
    "        other = torch.zeros(num, inp.shape[0] + num * 2)\n",
    "        return torch.cat([other, inp_pad, other])\n",
    "\n",
    "    def _pad_2d(self, inp: Tensor):\n",
    "        \n",
    "        outs = [_pad_2d_obs(obs, num) for obs in inp]\n",
    "        return torch.stack(outs)\n",
    "\n",
    "    def _compute_output_obs(self, \n",
    "                            obs: Tensor):\n",
    "        '''\n",
    "        Obs is a 2d square Tensor, so is param\n",
    "        '''\n",
    "        obs_pad = self._pad_2d_obs(obs)\n",
    "\n",
    "        out = torch.zeros(obs.shape)\n",
    "\n",
    "        for o_w in range(out.shape[0]):\n",
    "            for o_h in range(out.shape[1]):\n",
    "                for p_w in range(self.param_size):\n",
    "                    for p_h in range(self.param_size):\n",
    "                        out[o_w][o_h] += self.param_size[p_w][p_h] * obs_pad[o_w+p_w][o_h+p_h]\n",
    "        return out    \n",
    "\n",
    "    def _compute_output(self):\n",
    "\n",
    "        outs = [self._compute_output_obs(obs) for obs in self.input_]\n",
    "        return torch.stack(outs)\n",
    "\n",
    "    def _compute_grads_obs(self, \n",
    "                           input_obs: Tensor,\n",
    "                           output_grad_obs: Tensor) -> Tensor:\n",
    "\n",
    "        output_obs_pad = self._pad_2d_obs(output_grad_obs)\n",
    "        input_grad = torch.zeros_like(input_obs)\n",
    "\n",
    "        for i_w in range(input_obs.shape[0]):\n",
    "            for i_h in range(input_obs.shape[1]):\n",
    "                for p_w in range(param_size):\n",
    "                    for p_h in range(param_size):\n",
    "                        input_grad[i_w][i_h] += output_obs_pad[i_w+self.param_size-p_w-1][i_h+self.param_size-p_h-1] \\\n",
    "                        * self.param[p_w][p_h]\n",
    "\n",
    "        return input_grad\n",
    "\n",
    "    def _compute_grads(self, output_grad: Tensor) -> Tensor:\n",
    "\n",
    "        grads = [_compute_grads_obs(self.input_[i], output_grad[i], self.param) for i in range(output_grad.shape[0])]    \n",
    "\n",
    "        return torch.stack(grads)\n",
    "\n",
    "\n",
    "    def _param_grad(self, output_grad: Tensor) -> Tensor:\n",
    "\n",
    "        inp_pad = _pad_2d(self.input_)\n",
    "\n",
    "        param_grad = torch.zeros_like(self.param)\n",
    "        img_shape = output_grad.shape[1:]\n",
    "\n",
    "        for i in range(self.input_.shape[0]):\n",
    "            for o_w in range(img_shape[0]):\n",
    "                for o_h in range(img_shape[1]):\n",
    "                    for p_w in range(self.param_size):\n",
    "                        for p_h in range(self.param_size):\n",
    "                            param_grad[p_w][p_h] += inp_pad[i][o_w+p_w][o_h+p_h] \\\n",
    "                            * output_grad[i][o_w][o_h]\n",
    "        return param_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(ParamOperation):\n",
    "\n",
    "    def __init__(self, \n",
    "                 param: Tensor):\n",
    "        super().__init__(param)\n",
    "        self.param_size = param.shape[0]\n",
    "        self.param_pad = self.param_size // 2\n",
    "        \n",
    "    def _pad_1d_obs(self, obs: Tensor) -> Tensor:\n",
    "        z = torch.Tensor([0])\n",
    "        z = z.repeat(self.param_pad)\n",
    "        return torch.cat([z, obs, z])\n",
    "\n",
    "    def _pad_1d(self, inp: Tensor) -> Tensor:\n",
    "        outs = [self._pad_1d_obs(obs) for obs in inp]\n",
    "        return torch.stack(outs)\n",
    "        \n",
    "    def _pad_2d_obs(self,\n",
    "                    inp: Tensor):\n",
    "        '''\n",
    "        \"inp\" is a 2 dimensional tensor, representing (image width by image height) \n",
    "        '''\n",
    "        inp_pad = self._pad_1d_batch(inp, self.param_pad)\n",
    "        other = torch.zeros(num, inp.shape[0] + num * 2)\n",
    "        return torch.cat([other, inp_pad, other])\n",
    "\n",
    "    def _pad_2d_channel(self, inp: Tensor):\n",
    "        '''\n",
    "        \"inp\" is a 3 dimensional tensor, representing (image width by image height) \n",
    "        '''\n",
    "        num_channels = inp.shape[2]\n",
    "        return torch.stack([_pad_2d_obs(select_channel(inp, i), num) \n",
    "                            for i in range(num_channels)], dim=2)\n",
    "\n",
    "    def _pad_input(self, inp: Tensor):   \n",
    "        return torch.stack([_pad_2d_channel(obs) for obs in inp], dim=0)\n",
    "\n",
    "    \n",
    "    def _compute_output_obs(self, \n",
    "                            obs: Tensor):\n",
    "        '''\n",
    "        Obs is a 2d square Tensor, so is param\n",
    "        '''\n",
    "        obs_pad = self._pad_2d_obs(obs)\n",
    "\n",
    "        out = torch.zeros(obs.shape)\n",
    "\n",
    "        for o_w in range(out.shape[0]):\n",
    "            for o_h in range(out.shape[1]):\n",
    "                for p_w in range(self.param_size):\n",
    "                    for p_h in range(self.param_size):\n",
    "                        out[o_w][o_h] += self.param_size[p_w][p_h] * obs_pad[o_w+p_w][o_h+p_h]\n",
    "        return out    \n",
    "\n",
    "    def _compute_output(self):\n",
    "\n",
    "        outs = [self._compute_output_obs(obs) for obs in self.input_]\n",
    "        return torch.stack(outs)\n",
    "\n",
    "    def _compute_grads_obs(self, \n",
    "                           input_obs: Tensor,\n",
    "                           output_grad_obs: Tensor) -> Tensor:\n",
    "\n",
    "        output_obs_pad = self._pad_2d_obs(output_grad_obs)\n",
    "        input_grad = torch.zeros_like(input_obs)\n",
    "\n",
    "        for i_w in range(input_obs.shape[0]):\n",
    "            for i_h in range(input_obs.shape[1]):\n",
    "                for p_w in range(param_size):\n",
    "                    for p_h in range(param_size):\n",
    "                        input_grad[i_w][i_h] += output_obs_pad[i_w+self.param_size-p_w-1][i_h+self.param_size-p_h-1] \\\n",
    "                        * self.param[p_w][p_h]\n",
    "\n",
    "        return input_grad\n",
    "\n",
    "    def _compute_grads(self, output_grad: Tensor) -> Tensor:\n",
    "\n",
    "        grads = [_compute_grads_obs(self.input_[i], output_grad[i], self.param) for i in range(output_grad.shape[0])]    \n",
    "\n",
    "        return torch.stack(grads)\n",
    "\n",
    "\n",
    "    def _param_grad(self, output_grad: Tensor) -> Tensor:\n",
    "\n",
    "        inp_pad = _pad_2d(self.input_)\n",
    "\n",
    "        param_grad = torch.zeros_like(self.param)\n",
    "        img_shape = output_grad.shape[1:]\n",
    "\n",
    "        for i in range(self.input_.shape[0]):\n",
    "            for o_w in range(img_shape[0]):\n",
    "                for o_h in range(img_shape[1]):\n",
    "                    for p_w in range(self.param_size):\n",
    "                        for p_h in range(self.param_size):\n",
    "                            param_grad[p_w][p_h] += inp_pad[i][o_w+p_w][o_h+p_h] \\\n",
    "                            * output_grad[i][o_w][o_h]\n",
    "        return param_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(92718)\n",
    "batch_size = 5\n",
    "img_height = 4\n",
    "in_channels = 6\n",
    "out_channels = 9\n",
    "fil_size = 3\n",
    "inp = Tensor(torch.empty(batch_size, in_channels, img_height, img_height).uniform_(-1, 1))\n",
    "param = Tensor(torch.empty(out_channels, in_channels, fil_size, fil_size).uniform_(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6, 4, 4])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 4, 4])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_1 = inp[0]\n",
    "img_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_channel(inp: Tensor, i: int):\n",
    "    return torch.index_select(inp, dim=0, index=torch.LongTensor([i])).squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 4])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_channel(img_1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_2d_channel(inp: Tensor, num: int):\n",
    "    '''\n",
    "    \"inp\" is a 3 dimensional tensor, representing (image width by image height) \n",
    "    '''\n",
    "\n",
    "\n",
    "def _pad_conv_input(inp: Tensor, num: int):   \n",
    "    return torch.stack([_pad_2d_channel(obs, num) for obs in inp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6, 6, 6])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pad_conv_input(inp, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_output_obs(obs: Tensor, \n",
    "                        fil: Tensor):\n",
    "\n",
    "    param_size = fil.shape[2]\n",
    "    param_mid = param_size // 2\n",
    "    in_channels = obs.shape[0]\n",
    "    out_channels = fil.shape[0]\n",
    "    img_size = obs.shape[1]\n",
    "    obs_pad = _pad_2d_channel(obs, param_mid)\n",
    "    \n",
    "    out = torch.zeros((out_channels,) + obs.shape[1:])\n",
    "    for c_out in range(out_channels):\n",
    "        for c_in in range(in_channels):\n",
    "            for o_w in range(img_size):\n",
    "                for o_h in range(img_size):\n",
    "                    for p_w in range(param_size):\n",
    "                        for p_h in range(param_size):\n",
    "                            out[c_out][o_w][o_h] += \\\n",
    "                            fil[c_out][c_in][p_w][p_h] * obs_pad[c_in][o_w+p_w][o_h+p_h]\n",
    "    return out    \n",
    "\n",
    "def _compute_output(inp: Tensor,\n",
    "                    fil: Tensor) -> Tensor:\n",
    "\n",
    "    outs = [_compute_output_obs(obs, fil) for obs in inp]    \n",
    "\n",
    "    return torch.stack(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = _compute_output(inp, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.6228"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(torch.sum(out).item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 9, 4, 4])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 6, 3, 3])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_grads_obs(input_obs: Tensor,\n",
    "                       output_grad_obs: Tensor,\n",
    "                       fil: Tensor) -> Tensor:\n",
    "    '''\n",
    "    Input is dimension 3:\n",
    "    \n",
    "    '''\n",
    "    input_grad = torch.zeros_like(input_obs)    \n",
    "    param_size = fil.shape[2]\n",
    "    param_mid = param_size // 2\n",
    "    img_size = input_obs.shape[1]\n",
    "    in_channels = input_obs.shape[0]\n",
    "    out_channels = fil.shape[0]\n",
    "    output_obs_pad = _pad_2d_channel(output_grad_obs, param_mid)\n",
    "    \n",
    "    for c_in in range(in_channels):\n",
    "        for c_out in range(out_channels):\n",
    "            for i_w in range(input_obs.shape[1]):\n",
    "                for i_h in range(input_obs.shape[2]):\n",
    "                    for p_w in range(param_size):\n",
    "                        for p_h in range(param_size):\n",
    "                            input_grad[c_in][i_w][i_h] += \\\n",
    "                            output_obs_pad[c_out][i_w+param_size-p_w-1][i_h+param_size-p_h-1] \\\n",
    "                            * fil[c_out][c_in][p_w][p_h]\n",
    "    return input_grad\n",
    "\n",
    "def _compute_grads(inp: Tensor,\n",
    "                   output_grad: Tensor, \n",
    "                   fil: Tensor) -> Tensor:\n",
    "\n",
    "    grads = [_compute_grads_obs(inp[i], output_grad[i], fil) for i in range(output_grad.shape[0])]    \n",
    "\n",
    "    return torch.stack(grads)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp[0].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_grad = _compute_grads(inp, torch.ones_like(out), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.2669)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_grad[1][1][1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`inp_grad[1][1][1][1] == 4.2669`. This means that if we increase this value by 0.1, the sum of \"out\" will change to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.0495"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(33.6228 + 4.2669 * 0.1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_2 = inp.clone()\n",
    "inp_2[1][1][1][1] += 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.0495"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = _compute_output(inp_2, param)\n",
    "round(torch.sum(out).item(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### param_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _param_grad(inp: Tensor,\n",
    "                output_grad: Tensor, \n",
    "                fil: Tensor) -> Tensor:\n",
    "\n",
    "    param_grad = torch.zeros_like(fil)    \n",
    "    param_size = fil.shape[2]\n",
    "    param_mid = param_size // 2\n",
    "    img_size = inp.shape[2]\n",
    "    in_channels = inp.shape[1]\n",
    "    out_channels = output_grad.shape[1]    \n",
    "\n",
    "    inp_pad = _pad_conv_input(inp, param_mid)\n",
    "    img_shape = output_grad.shape[2:]\n",
    "\n",
    "    for i in range(inp.shape[0]):\n",
    "        for c_in in range(in_channels):\n",
    "            for c_out in range(out_channels):\n",
    "                for o_w in range(img_shape[0]):\n",
    "                    for o_h in range(img_shape[1]):\n",
    "                        for p_w in range(param_size):\n",
    "                            for p_h in range(param_size):\n",
    "                                param_grad[c_out][c_in][p_w][p_h] += \\\n",
    "                                inp_pad[i][c_in][o_w+p_w][o_h+p_h] \\\n",
    "                                * output_grad[i][c_out][o_w][o_h]\n",
    "    return param_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grad = _param_grad(inp, torch.ones_like(out), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7363)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param[2][2][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.4440)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_grad[2][2][2][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`p_grad[2][2][2][2] == -3.4440`. This means that if we increase this value by 0.1, the sum of \"out\" will change to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.2784"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(33.6228 + -3.4440 * 0.1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_2 = param.clone()\n",
    "param_2[2][2][2][2] += 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(33.6228)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(_compute_output(inp, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(33.2784)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(_compute_output(inp, param_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_1d_obs_np(obs, pad):\n",
    "    a = np.zeros(pad)\n",
    "    z = np.concatenate([a, obs, a])\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_1d_np(inp, pad):\n",
    "    return np.stack([_pad_1d_obs_np(obs, pad) for obs in inp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_2d_obs_np(inp, pad):\n",
    "    inp_pad = _pad_1d_np(inp, pad)\n",
    "    other = np.zeros((pad, inp.shape[0] + pad * 2))\n",
    "    return np.concatenate([other, inp_pad, other])\n",
    "\n",
    "\n",
    "def _pad_2d_batch_np(inp, pad):\n",
    "    return np.stack([_pad_2d_obs_np(obs, pad) for obs in inp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 4, 4])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1_np = img_1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_2d_channel(inp: Tensor, num: int):\n",
    "    '''\n",
    "    \"inp\" is a 3 dimensional tensor, representing (image width by image height) \n",
    "    '''\n",
    "    num_channels = inp.shape[0]\n",
    "    return torch.stack([_pad_2d_obs(inp[i], num) for i in range(num_channels)])\n",
    "\n",
    "def _pad_conv_input(inp: Tensor, num: int):   \n",
    "    return torch.stack([_pad_2d_channel(obs, num) for obs in inp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 6, 6])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pad_2d_channel(img_1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_2d_channel_np(inp, num):\n",
    "    return np.stack([_pad_2d_obs_np(channel, num) for channel in inp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6, 6)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pad_2d_channel_np(img_1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6, 6, 6])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _pad_conv_input(inp: Tensor, num: int):   \n",
    "    return torch.stack([_pad_2d_channel(obs, num) for obs in inp])\n",
    "_pad_conv_input(inp, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_conv_input_np(inp, num):   \n",
    "    return np.stack([_pad_2d_channel_np(obs, num) for obs in inp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 6, 6, 6)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pad_conv_input_np(inp.numpy(), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_1d_obs_cy(obs, pad):\n",
    "    a = np.zeros(pad)\n",
    "    z = np.concatenate([a, obs, a])\n",
    "    return z\n",
    "\n",
    "\n",
    "def _pad_1d_batch_cy(inp, pad):\n",
    "    return np.stack([_pad_1d_obs_cy(obs, pad) for obs in inp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_2d_obs_cy(inp, pad):\n",
    "    inp_pad = _pad_1d_batch_cy(inp, pad)\n",
    "    other = np.zeros((pad, inp.shape[0] + pad * 2))\n",
    "    return np.concatenate([other, inp_pad, other])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_2d_channel_cy(inp, pad):\n",
    "    return np.stack([_pad_2d_obs_cy(channel, pad) for channel in inp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_output_obs_cy(inp, param):\n",
    "\n",
    "    param_size = param.shape[2]\n",
    "    in_channels = inp.shape[0]\n",
    "    out_channels = param.shape[0]\n",
    "    param_mid = param_size // 2\n",
    "    img_size = inp.shape[1]\n",
    "\n",
    "    obs_pad = _pad_2d_channel_cy(inp, param_mid)\n",
    "\n",
    "    out = np.zeros((out_channels, img_size, img_size))\n",
    "\n",
    "    for c_out in range(out_channels):\n",
    "        for c_in in range(in_channels):\n",
    "            for o_w in range(img_size):\n",
    "                for o_h in range(img_size):\n",
    "                    for p_w in range(param_size):\n",
    "                        for p_h in range(param_size):\n",
    "                              out[c_out][o_w][o_h] += \\\n",
    "                              param[c_out][c_in][p_w][p_h] * \\\n",
    "                              obs_pad[c_in][o_w+p_w][o_h+p_h]\n",
    "    return out\n",
    "\n",
    "\n",
    "def _output_cy(inp, param):\n",
    "\n",
    "    return np.stack([_compute_output_obs_cy(obs, param) for obs in inp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.random.uniform(size=(2,1,28,28))\n",
    "param = np.random.uniform(size=(24,1,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 24, 28, 28)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_output_cy(inp, param).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "batch_size = 5\n",
    "img_size = 28\n",
    "n_channels = 1\n",
    "inp = Tensor(torch.empty(batch_size, \n",
    "                       n_channels,\n",
    "                       img_size, \n",
    "                       img_size).uniform_(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 28, 28])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2 = inp.detach() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 28, 28])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 4\n",
    "op = nn.Conv2d(1, 4, 3, padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.conv.Conv2d"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = op(inp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 28, 28])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-e18bf04c54ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "inp2.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.backward(gradient=torch.ones_like(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 28, 28])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp2.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[53.6569, 55.5921, 53.9341],\n",
       "          [61.2716, 62.0950, 61.3836],\n",
       "          [67.9083, 67.9084, 67.8764]]],\n",
       "\n",
       "\n",
       "        [[[53.6569, 55.5921, 53.9341],\n",
       "          [61.2716, 62.0950, 61.3836],\n",
       "          [67.9083, 67.9084, 67.8764]]],\n",
       "\n",
       "\n",
       "        [[[53.6569, 55.5921, 53.9341],\n",
       "          [61.2716, 62.0950, 61.3836],\n",
       "          [67.9083, 67.9084, 67.8764]]],\n",
       "\n",
       "\n",
       "        [[[53.6569, 55.5921, 53.9341],\n",
       "          [61.2716, 62.0950, 61.3836],\n",
       "          [67.9083, 67.9084, 67.8764]]]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 3, 3])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.weight.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in b.:\n",
    "    print(p.grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
